{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"Bespokefit_smee <p>Generate a Bespoke Force-Field Parametrization Quickly and Reliably. Developed in the Cole Group at Newcastle University. Please see the documentation.</p> <p>Warning: This code is experimental and under active development. It is not guaranteed to provide correct results, the documentation and testing is incomplete, and the API may change without notice.</p> <p>Please note that the MACE models currently used are released under the Academic Software License which does not permit commercial use. We will incorporate MIT-licensed models soon.</p>"},{"location":"#what-is-bespokefit_smee","title":"What is Bespokefit_smee?","text":"<p>Bespokefit_smee is a Force-Field parametrization tool. For a given molecule, it will generate a data set of conformers using machine learning models in OpenMM-ML simulations. This dataset is used to optimise the force field parameters.</p>"},{"location":"#installation","title":"Installation","text":"<p>Ensuring that you have mamba installed, run: <pre><code>git clone https://github.com/fjclark/bespokefit_smee.git\ncd bespokefit_smee\nmake install\n</code></pre></p>"},{"location":"#usage","title":"Usage","text":"<p>Run with command line arguments: <pre><code>bespokefit_smee train --smiles \"CCC(CC)C(=O)Nc2cc(NC(=O)c1c(Cl)cccc1Cl)ccn2\"\n</code></pre></p> <p>Sensible defaults have been set, but all available options can be viewed with: <pre><code>bespokefit_smee train --help\n</code></pre></p> <p>Analyse with: <pre><code>bespokefit_smee analyse training_config.yaml # This will have been generated by the training command\n</code></pre></p> <p>Run from a yaml file: <pre><code>bespokefit_smee write-default-yaml default.yaml\n# Modify the yaml to set the desired smiles\nbespokefit_smee train-from-yaml default.yaml\n</code></pre></p> <p>For more details on the theory and implementation, please see the documentation.</p>"},{"location":"#copyright","title":"Copyright","text":"<p>Copyright (c) 2025, Thomas James Pope, Newcastle University, UK</p> <p>Copyright (c) 2025, Finlay Clark, Newcastle University, UK</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>All early development was completed by Thomas James Pope. Many ideas taken from Simon Boothroyd's super helpful python-template.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"development/","title":"Development","text":""},{"location":"development/#writing-code","title":"Writing Code","text":"<p>To create a development environment, you must have <code>mamba</code> installed.</p> <p>A development conda environment can be created and activated with:</p> <pre><code>make env\nmamba activate red\n</code></pre> <p>Some handy <code>make</code> commands are available: <pre><code>make lint # Lint the codebase with Ruff\nmake format # Format the codebase with Ruff\nmake type-check # Type-check the codebase with Mypy\nmake test # Run the unit tests with Pytest\n</code></pre></p> <p>To serve the documentation locally:</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"development/#publishing","title":"Publishing","text":""},{"location":"development/#pypi","title":"PyPI","text":"<p>There is a GitHub Actions workflow that will automatically publish to PyPI when a new tag is pushed: <pre><code>git tag &lt;new version&gt;\ngit push origin &lt;new version&gt;\n</code></pre></p>"},{"location":"theory/","title":"Theory","text":"<p>From a SMILES string, we generate a initial parametrization using a default open-ff force field - and optionally, adding in modified-Seminario derived bond and angle force constants. This is used to generate a dataset of conformers by running either ML-Potential MD of Force-Field MD and grabbing a number of snapshots. For every snapshot, the energies and forces are taken using the ML-Potental.</p> <p>This dataset is used to minimize the given force field parameters using the ADAM stochastic optimization method, where the loss function is the squared difference between energies and forces for the conformer dataset predicted by the force-field parametrization and the stored values calculated with the ML-potential.</p> <p>After a given number of epochs, the new parametrization is stored. The new force-field is used to generate another set of MD snapshots, which are used in the same way to further optimize the force field. This continues for a given number of iterations, where the relative reduction is error is tracked. The number of iterations should be increased up to convergence.</p> <p>Four methods for generating the initial dataset are implemented:</p> <p>1 - \"DATA\" : Read the dataset from a file</p> <p>2 - \"MLMD\" : Run the ML-Potential MD to get the snapshots. This is the most expensive option.</p> <p>3 - \"MMMD\" : Run Force-Field MD using the initial guess to generate the snapshots. Then use the ML-Potential to generate energies and forces</p> <p>4 - \"cMMMD\" : Run Force-Field MD using the initial guess to generate the snapshots. Cluster the snapshots with respect to their pairwise RMSD and then use the ML-Potential to generate energies and forces</p> <p>The functional form of the force-field is as follows:</p> <ul> <li>Bonds and angles are defined by a harmonic function, \\(u(x;k,x_0)=\\frac{k}{2}\\left(x-x_0\\right)^2\\), where the position of the minimum, \\(x_0\\), and the magnitude, \\(k\\), are the fitting parameters.</li> <li>Proper and improper torsions are defined by a set of cosine functions, \\(u_p(\\phi;k,\\phi_0)=k\\left(1+\\cos{\\left(p\\phi-\\phi_0\\right)}\\right)\\), where the phase, \\(\\phi_0\\), and the magnitude, \\(k\\), are the fitted parameters. Here, proper torsions are expanded to include four periodicities, whereas improper torsions include only one. It is also noted that for symmetry, the phase \\(\\phi_0\\) is expected to be either 0 or \\(\\pi\\)</li> </ul> <p>To stabilize and speed up convergence of the parameter fitting, these potentials are linearized.</p> <p>The linearization of the harmonic terms followed the approach by espaloma, where the minimum is assumed to be within a window given by \\(x_1\\) and \\(x_2\\), such that the fitting parameters may by remapped onto linear terms,</p> \\[k_1=k\\frac{x_2-x_0}{x_2-x_1} \\quad\\text{and}\\quad k_2=k\\frac{x_0-x_1}{x_2-x_1}\\] <p>These terms give the original parameters via,</p> \\[k=k_1+k_2 \\quad\\text{and}\\quad x_0=\\frac{k_1x_1+k_2x_2}{k_1+k_2}\\] <p>Crucially, the gradient along \\(k_1\\) and \\(k_2\\) behaves more reliably and so the parameters minimize faster.</p> <p>In a similar way, the cosine functions are linearized by defining a phase window of 0 to \\(\\pi\\), such that the parameters may be mapped onto,</p> \\[k_0=\\frac{k}{2}\\left(1+\\cos{\\phi_0}\\right) \\quad\\text{and}\\quad k_{\\pi}=\\frac{k}{2}\\left(1-\\cos{\\phi_0}\\right)\\] <p>which yield the original parameters via,</p> \\[k=k_0+k_{\\pi} \\quad\\text{and}\\quad \\cos{\\phi_0}=\\frac{k_0-k_{\\pi}}{k_0+k_{\\pi}}\\] <p>Again, the gradient along \\(k_0\\) and \\(k_{\\pi}\\) is more reliable and the parametrization proceed faster.</p>"},{"location":"reference/","title":"Index","text":""},{"location":"reference/#bespokefit_smee","title":"bespokefit_smee","text":"<p>Generate a Force-Field Parameterization from Higher-Level MD</p> <p>Modules:</p> <ul> <li> <code>analysis</code>           \u2013            <p>Functionality for analysing the results of a BespokeFitSMEE run.</p> </li> <li> <code>data_maker</code>           \u2013            <p>Functionality to obtain samples, to which the force field is fitted.</p> </li> <li> <code>loss_functions</code>           \u2013            <p>Loss functions for tuning the forcefield</p> </li> <li> <code>mlp</code>           \u2013            <p>Functionality for creating Open</p> </li> <li> <code>parameterizer</code>           \u2013            <p>PARAMETERIZE:</p> </li> <li> <code>settings</code>           \u2013            <p>Pydantic models which control/validate the settings.</p> </li> <li> <code>tests</code>           \u2013            <p>Unit and integration tests for bespokefit_smee</p> </li> <li> <code>train</code>           \u2013            <p>Apply OpenFF parameters to molecule, cluster conformers by RMSD and train</p> </li> <li> <code>utils</code>           \u2013            <p>Utilities for the bespokefit_smee package.</p> </li> <li> <code>writers</code>           \u2013            <p>WRITERS:</p> </li> </ul>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>bespokefit_smee<ul> <li>analysis</li> <li>data_maker</li> <li>loss_functions</li> <li>mlp</li> <li>parameterizer</li> <li>settings</li> <li>train</li> <li>utils<ul> <li>aimnet2</li> <li>typing</li> </ul> </li> <li>writers</li> </ul> </li> </ul>"},{"location":"reference/analysis/","title":"analysis","text":""},{"location":"reference/analysis/#bespokefit_smee.analysis","title":"analysis","text":"<p>Functionality for analysing the results of a BespokeFitSMEE run.</p> <p>Classes:</p> <ul> <li> <code>OutputData</code>           \u2013            <p>Dataclass to store the output data from the calculations</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>plot_error_statistics</code>             \u2013              <p>Plot the error statistics for the energy and force errors.</p> </li> <li> <code>plot_all</code>             \u2013              <p>Plot all the results from the BespokeFitSMEE run.</p> </li> </ul>"},{"location":"reference/analysis/#bespokefit_smee.analysis.OutputData","title":"OutputData  <code>dataclass</code>","text":"<pre><code>OutputData(training_config: TrainingConfig)\n</code></pre> <p>Dataclass to store the output data from the calculations</p> <p>Attributes:</p> <ul> <li> <code>training_config</code>               (<code>TrainingConfig</code>)           \u2013            <p>The config specifying the training parameters.</p> </li> <li> <code>path</code>               (<code>Path</code>)           \u2013            <p>Path to the output directory.</p> </li> </ul>"},{"location":"reference/analysis/#bespokefit_smee.analysis.OutputData.training_config","title":"training_config  <code>instance-attribute</code>","text":"<pre><code>training_config: TrainingConfig\n</code></pre> <p>The config specifying the training parameters.</p>"},{"location":"reference/analysis/#bespokefit_smee.analysis.OutputData.path","title":"path  <code>property</code>","text":"<pre><code>path: Path\n</code></pre> <p>Path to the output directory.</p>"},{"location":"reference/analysis/#bespokefit_smee.analysis.plot_error_statistics","title":"plot_error_statistics","text":"<pre><code>plot_error_statistics(\n    fig: Figure, axs: NDArray[Any], output_data: OutputData\n) -&gt; None\n</code></pre> <p>Plot the error statistics for the energy and force errors.</p> Source code in <code>bespokefit_smee/analysis.py</code> <pre><code>def plot_error_statistics(\n    fig: Figure, axs: npt.NDArray[Any], output_data: OutputData\n) -&gt; None:\n    \"\"\"Plot the error statistics for the energy and force errors.\"\"\"\n\n    axs = axs.flatten()\n    plot_distributions_of_errors(fig, axs[0], output_data, \"energy\")\n    plot_distributions_of_errors(fig, axs[1], output_data, \"force\")\n    # Hide the legend in the first plot\n    axs[0].legend().set_visible(False)\n\n    # Plot the rmsds of the errors\n    plot_rmse_of_errors(fig, axs[2], output_data, \"energy\")\n    plot_rmse_of_errors(fig, axs[3], output_data, \"force\")\n\n    # Plot the mean errors\n    # plot_mean_errors(fig, axs[4], output_data, \"energy\")\n    # plot_mean_errors(fig, axs[5], output_data, \"force\")\n\n    # # Plot the standard deviation of the errors\n    plot_sd_of_errors(fig, axs[4], output_data, \"energy\")\n    plot_sd_of_errors(fig, axs[5], output_data, \"force\")\n</code></pre>"},{"location":"reference/analysis/#bespokefit_smee.analysis.plot_all","title":"plot_all","text":"<pre><code>plot_all(output_data: OutputData) -&gt; None\n</code></pre> <p>Plot all the results from the BespokeFitSMEE run.</p> Source code in <code>bespokefit_smee/analysis.py</code> <pre><code>def plot_all(output_data: OutputData) -&gt; None:\n    \"\"\"Plot all the results from the BespokeFitSMEE run.\"\"\"\n\n    with plt.style.context(PLT_STYLE):\n        # Plot the loss\n        fig, ax = plt.subplots(figsize=(10, 6))\n        plot_loss(fig, ax, output_data)\n        fig.savefig(str(output_data.path / \"loss.png\"), dpi=300, bbox_inches=\"tight\")\n\n        # Plot the error statistics\n        fig, axs = plt.subplots(3, 2, figsize=(13, 18))\n        plot_error_statistics(fig, axs, output_data)\n        fig.savefig(\n            str(output_data.path / \"error_distributions.png\"),\n            dpi=300,\n            bbox_inches=\"tight\",\n        )\n</code></pre>"},{"location":"reference/data_maker/","title":"data_maker","text":""},{"location":"reference/data_maker/#bespokefit_smee.data_maker","title":"data_maker","text":"<p>Functionality to obtain samples, to which the force field is fitted.</p> <p>Functions:</p> <ul> <li> <code>get_data_MMMD</code>             \u2013              <p>generate a dataset from an openmm run using the input FF.</p> </li> <li> <code>get_data_MLMD</code>             \u2013              <p>generate a dataset from an openmm run using the input ML Potential.</p> </li> <li> <code>get_data_cMMMD</code>             \u2013              <p>generate a dataset from an openmm run using the input FF</p> </li> </ul>"},{"location":"reference/data_maker/#bespokefit_smee.data_maker.get_data_MMMD","title":"get_data_MMMD","text":"<pre><code>get_data_MMMD(\n    mol: Molecule,\n    off: ForceField,\n    ML_path: AvailableModels = \"mace-off23-small\",\n    temperature: float = 300,\n    dt: float = 0.001,\n    N: int = 1000,\n    Nc: int = 1,\n    MD_stepsize: int = 10,\n    MD_startup: int = 100,\n    MD_energy_upper_cutoff: float = 10.0,\n    MD_energy_lower_cutoff: float = 1.0,\n    cluster_tolerance: float = 0.075,\n    cluster_Parallel: int = 1,\n) -&gt; Dataset\n</code></pre> <p>generate a dataset from an openmm run using the input FF. Returns:     A dataset full of MD snapshops with their energies and forces</p> Source code in <code>bespokefit_smee/data_maker.py</code> <pre><code>def get_data_MMMD(\n    mol: openff.toolkit.Molecule,\n    off: openff.toolkit.ForceField,\n    ML_path: mlp.AvailableModels = \"mace-off23-small\",\n    temperature: float = 300,\n    dt: float = 0.001,\n    N: int = 1000,\n    Nc: int = 1,\n    MD_stepsize: int = 10,\n    MD_startup: int = 100,\n    MD_energy_upper_cutoff: float = 10.0,\n    MD_energy_lower_cutoff: float = 1.0,\n    cluster_tolerance: float = 0.075,\n    cluster_Parallel: int = 1,\n) -&gt; datasets.Dataset:\n    \"\"\"generate a dataset from an openmm run using the input FF.\n    Returns:\n        A dataset full of MD snapshops with their energies and forces\n    \"\"\"\n    # set up an openmm simulation\n    molecule = copy.deepcopy(mol)\n    molecule.generate_conformers(n_conformers=Nc, rms_cutoff=0.0 * _ANGSTROM)\n    interchange = openff.interchange.Interchange.from_smirnoff(\n        off, openff.toolkit.Topology.from_molecules(molecule)\n    )\n    integrator = LangevinMiddleIntegrator(\n        temperature * _OMM_KELVIN, 1 / _OMM_PS, dt * _OMM_PS\n    )\n    simulation_ff = interchange.to_openmm_simulation(integrator)\n    # minimize the system energy and take a snapshot for the ground-state reference\n    coords, energy, forces, weight = [], [], [], []\n    for conformer in tqdm(\n        molecule.conformers,\n        leave=False,\n        colour=\"green\",\n        desc=\"Generating Snapshots\",\n    ):\n        interchange.positions = conformer\n        simulation_ff.context.setPositions(interchange.positions.to_openmm())\n        simulation_ff.minimizeEnergy(maxIterations=100)\n        coords.append(\n            simulation_ff.context.getState(getPositions=True)\n            .getPositions()\n            .value_in_unit(_OMM_ANGS)\n        )\n        simulation_ff.step(MD_startup)\n        # run the MD and take snapshots\n        for _ in tqdm(range(N - 1), leave=False, colour=\"red\", desc=\"Running MD\"):\n            simulation_ff.step(MD_stepsize)\n            coords.append(\n                simulation_ff.context.getState(getPositions=True)\n                .getPositions()\n                .value_in_unit(_OMM_ANGS)\n            )\n    coords_out = torch.tensor(coords)\n    # Generate energy and force for the snapshots using a ML potential\n    potential = mlp.get_mlp(ML_path)\n    with open(\"/dev/null\", \"w\") as f:\n        with redirect_stdout(f):\n            system = potential.createSystem(\n                interchange.to_openmm_topology(),\n                charge=mol.total_charge.m_as(off_unit.e),\n            )\n    integrator = copy.copy(integrator)\n    simulation_ml = Simulation(interchange.topology, system, integrator)\n    for i in tqdm(\n        range(N * Nc),\n        leave=False,\n        colour=\"green\",\n        desc=\"Calculating Energies and Forces\",\n    ):\n        my_pos = Quantity(numpy.array(coords_out[i]), angstrom)\n        simulation_ml.context.setPositions(my_pos)\n        state = simulation_ml.context.getState(getEnergy=True, getForces=True)\n        energy.append(state.getPotentialEnergy().value_in_unit(_OMM_KCAL_PER_MOL))\n        forces.append(\n            state.getForces(asNumpy=True).value_in_unit(_OMM_KCAL_PER_MOL_ANGS)\n        )\n        weight.append(1.0)\n        # delE = energy[i] - energy[0]\n        # if delE &lt; MD_energy_lower_cutoff:\n        #     weight.append(1.0)\n        # elif delE &gt; MD_energy_upper_cutoff:\n        #     weight.append(0.0)\n        # else:\n        #     weight.append(1.0 / math.sqrt(1.0 + (delE - 1.0) ** 2))\n    smiles = mol.to_smiles(isomeric=True, explicit_hydrogens=True, mapped=True)\n    energy_0 = energy[0]\n    energy_out = torch.tensor([x - energy_0 for x in energy])\n    forces_out = torch.tensor(forces)\n\n    return descent.targets.energy.create_dataset(\n        [\n            {\n                \"smiles\": smiles,\n                \"coords\": coords_out,\n                \"energy\": energy_out,\n                \"forces\": forces_out,\n            }\n        ]\n    )\n</code></pre>"},{"location":"reference/data_maker/#bespokefit_smee.data_maker.get_data_MLMD","title":"get_data_MLMD","text":"<pre><code>get_data_MLMD(\n    mol: Molecule,\n    off: ForceField,\n    ML_path: AvailableModels = \"mace-off23-small\",\n    temperature: float = 300,\n    dt: float = 0.001,\n    N: int = 1000,\n    Nc: int = 1,\n    MD_stepsize: int = 10,\n    MD_startup: int = 100,\n    MD_energy_upper_cutoff: float = 10.0,\n    MD_energy_lower_cutoff: float = 1.0,\n    cluster_tolerance: float = 0.075,\n    cluster_Parallel: int = 1,\n) -&gt; Dataset\n</code></pre> <p>generate a dataset from an openmm run using the input ML Potential. Returns:     A dataset full of MD snapshops with their energies and forces</p> Source code in <code>bespokefit_smee/data_maker.py</code> <pre><code>def get_data_MLMD(\n    mol: openff.toolkit.Molecule,\n    off: openff.toolkit.ForceField,\n    ML_path: mlp.AvailableModels = \"mace-off23-small\",\n    temperature: float = 300,\n    dt: float = 0.001,\n    N: int = 1000,\n    Nc: int = 1,\n    MD_stepsize: int = 10,\n    MD_startup: int = 100,\n    MD_energy_upper_cutoff: float = 10.0,\n    MD_energy_lower_cutoff: float = 1.0,\n    cluster_tolerance: float = 0.075,\n    cluster_Parallel: int = 1,\n) -&gt; datasets.Dataset:\n    \"\"\"generate a dataset from an openmm run using the input ML Potential.\n    Returns:\n        A dataset full of MD snapshops with their energies and forces\n    \"\"\"\n    # set up an openmm simulation\n    molecule = copy.deepcopy(mol)\n    molecule.generate_conformers(n_conformers=Nc, rms_cutoff=0.0 * _ANGSTROM)\n    force_field = copy.deepcopy(off)\n    interchange = openff.interchange.Interchange.from_smirnoff(\n        force_field, openff.toolkit.Topology.from_molecules(molecule)\n    )\n    integrator = LangevinMiddleIntegrator(\n        temperature * _OMM_KELVIN, 1 / _OMM_PS, dt * _OMM_PS\n    )\n    potential = mlp.get_mlp(ML_path)\n    with open(\"/dev/null\", \"w\") as f:\n        with redirect_stdout(f):\n            system = potential.createSystem(\n                interchange.to_openmm_topology(),\n                charge=mol.total_charge.m_as(off_unit.e),\n            )\n    simulation = Simulation(interchange.topology, system, integrator)\n\n    coords, energy, forces, weight = [], [], [], []\n    for conformer in tqdm(\n        list(molecule.conformers),\n        leave=False,\n        colour=\"green\",\n        desc=\"Generating Dataset\",\n    ):\n        interchange.positions = conformer\n        position = interchange.positions.to_openmm()\n        simulation.context.setPositions(position)\n        simulation.minimizeEnergy(maxIterations=100)\n        state = simulation.context.getState(\n            getPositions=True, getEnergy=True, getForces=True\n        )\n        coords.append(state.getPositions().value_in_unit(_OMM_ANGS))\n        energy.append(state.getPotentialEnergy().value_in_unit(_OMM_KCAL_PER_MOL))\n        forces.append(\n            state.getForces(asNumpy=True).value_in_unit(_OMM_KCAL_PER_MOL_ANGS)\n        )\n        weight.append(1.0)\n        simulation.step(MD_startup)\n        for _ in tqdm(range(N - 1), leave=False, colour=\"red\"):\n            simulation.step(MD_stepsize)\n            state = simulation.context.getState(\n                getPositions=True, getEnergy=True, getForces=True\n            )\n            coords.append(state.getPositions().value_in_unit(_OMM_ANGS))\n            energy.append(state.getPotentialEnergy().value_in_unit(_OMM_KCAL_PER_MOL))\n            forces.append(\n                state.getForces(asNumpy=True).value_in_unit(_OMM_KCAL_PER_MOL_ANGS)\n            )\n            weight.append(1.0)\n            # delE = energy[i] - energy[0]\n            # if delE &lt; MD_energy_lower_cutoff:\n            #     weight.append(1.0)\n            # elif delE &gt; MD_energy_upper_cutoff:\n            #     weight.append(0.0)\n            # else:\n            #     weight.append(1.0 / math.sqrt(1.0 + (delE - 1.0) ** 2))\n    energy_0 = energy[0]\n    energy_out = torch.tensor([x - energy_0 for x in energy])\n    forces_out = torch.tensor(forces)\n    coords_out = torch.tensor(coords)\n    smiles = mol.to_smiles(isomeric=True, explicit_hydrogens=True, mapped=True)\n    return descent.targets.energy.create_dataset(\n        [\n            {\n                \"smiles\": smiles,\n                \"coords\": coords_out,\n                \"energy\": energy_out,\n                \"forces\": forces_out,\n            }\n        ]\n    )\n</code></pre>"},{"location":"reference/data_maker/#bespokefit_smee.data_maker.get_data_cMMMD","title":"get_data_cMMMD","text":"<pre><code>get_data_cMMMD(\n    mol: Molecule,\n    off: ForceField,\n    ML_path: AvailableModels = \"mace-off23-small\",\n    temperature: float = 300,\n    dt: float = 0.001,\n    N: int = 1000,\n    Nc: int = 1,\n    MD_stepsize: int = 10,\n    MD_startup: int = 100,\n    MD_energy_upper_cutoff: float = 10.0,\n    MD_energy_lower_cutoff: float = 1.0,\n    cluster_tolerance: float = 0.075,\n    cluster_Parallel: int = 1,\n) -&gt; Dataset\n</code></pre> <p>generate a dataset from an openmm run using the input FF and cluster the data by rmsd and include counts in the weights Returns:     A dataset full of MD snapshops with their energies and forces</p> Source code in <code>bespokefit_smee/data_maker.py</code> <pre><code>def get_data_cMMMD(\n    mol: openff.toolkit.Molecule,\n    off: openff.toolkit.ForceField,\n    ML_path: mlp.AvailableModels = \"mace-off23-small\",\n    temperature: float = 300,\n    dt: float = 0.001,\n    N: int = 1000,\n    Nc: int = 1,\n    MD_stepsize: int = 10,\n    MD_startup: int = 100,\n    MD_energy_upper_cutoff: float = 10.0,\n    MD_energy_lower_cutoff: float = 1.0,\n    cluster_tolerance: float = 0.075,\n    cluster_Parallel: int = 1,\n) -&gt; datasets.Dataset:\n    \"\"\"generate a dataset from an openmm run using the input FF\n    and cluster the data by rmsd and include counts in the weights\n    Returns:\n        A dataset full of MD snapshops with their energies and forces\n    \"\"\"\n    # set up an openmm simulation\n    molecule = copy.deepcopy(mol)\n    molecule.generate_conformers(n_conformers=Nc, rms_cutoff=0.0 * _ANGSTROM)\n    interchange = openff.interchange.Interchange.from_smirnoff(\n        off, openff.toolkit.Topology.from_molecules(molecule)\n    )\n    integrator = LangevinMiddleIntegrator(\n        temperature * _OMM_KELVIN, 1 / _OMM_PS, dt * _OMM_PS\n    )\n    simulation_ff = interchange.to_openmm_simulation(integrator)\n    # minimize the system energy and take a snapshot for the ground-state reference\n    coords: list[float] = []\n    energy: list[float] = []\n    forces: list[float] = []\n    weight: list[float] = []\n    for conformer in tqdm(\n        molecule.conformers,\n        leave=False,\n        colour=\"green\",\n        desc=\"Generating Snapshots\",\n    ):\n        interchange.positions = conformer\n        simulation_ff.context.setPositions(interchange.positions.to_openmm())\n        simulation_ff.minimizeEnergy(maxIterations=100)\n        coords.append(\n            simulation_ff.context.getState(getPositions=True)\n            .getPositions()\n            .value_in_unit(_OMM_ANGS)\n        )\n        simulation_ff.step(MD_startup)\n        # run the MD and take snapshots\n        for _ in tqdm(range(N - 1), leave=False, colour=\"red\", desc=\"Running MD\"):\n            simulation_ff.step(MD_stepsize)\n            coords.append(\n                simulation_ff.context.getState(getPositions=True)\n                .getPositions()\n                .value_in_unit(_OMM_ANGS)\n            )\n    coords_out = torch.tensor(coords)\n    # Cluster the coordinates based on rmsd\n    coords_clstr = coords_out.reshape(N * Nc, -1, 3).tolist()\n    coords_clstr = [c * _ANGSTROM for c in coords_clstr]\n    mol_clstr = copy.deepcopy(mol)\n    mol_clstr._conformers = coords_clstr\n    mol_rdkit: Chem.Mol = Chem.RemoveHs(mol_clstr.to_rdkit())\n    conf_ids = [conf.GetId() for conf in mol_rdkit.GetConformers()]\n    conf_pairs = [(i, j) for i in range(len(conf_ids)) for j in range(i)]\n    conf_pairs_np = numpy.array_split(numpy.array(conf_pairs), cluster_Parallel)\n    rms_fn = functools.partial(compute_best_rms, mol=mol_rdkit)\n    with multiprocessing.Pool(cluster_Parallel) as pool:\n        dists = list(\n            tqdm(\n                pool.imap(rms_fn, conf_pairs_np),\n                total=len(conf_pairs_np),\n                leave=False,\n                colour=\"green\",\n                desc=\"Clustering the Conformers\",\n            )\n        )\n    dists_flat = [d for dist in dists for d in dist]\n    clusters = Butina.ClusterData(  # type: ignore[no-untyped-call]\n        dists_flat, len(conf_ids), cluster_tolerance, isDistData=True, reordering=True\n    )\n    cluster_ids = [cluster[0] for cluster in clusters]\n    cluster_len = [len(cluster) for cluster in clusters]\n    tqdm.write(f\"Clustering Summary: {len(conf_ids)} -&gt; {len(cluster_ids)}\")\n    coords_use = coords_out[cluster_ids, :, :]\n    # Generate energy and force for the snapshots using a ML potential\n    potential = mlp.get_mlp(ML_path)\n    with open(\"/dev/null\", \"w\") as f:\n        with redirect_stdout(f):\n            system = potential.createSystem(\n                interchange.to_openmm_topology(),\n                charge=mol.total_charge.m_as(off_unit.e),\n            )\n    integrator = copy.copy(integrator)\n    simulation_ml = Simulation(interchange.topology, system, integrator)\n    for i in tqdm(\n        range(len(cluster_ids)),\n        leave=False,\n        colour=\"green\",\n        desc=\"Calculating Energies and Forces\",\n    ):\n        my_pos = Quantity(numpy.array(coords_use[i]), angstrom)\n        simulation_ml.context.setPositions(my_pos)\n        state = simulation_ml.context.getState(getEnergy=True, getForces=True)\n        energy.append(state.getPotentialEnergy().value_in_unit(_OMM_KCAL_PER_MOL))\n        forces.append(\n            state.getForces(asNumpy=True).value_in_unit(_OMM_KCAL_PER_MOL_ANGS)\n        )\n        weight.append(cluster_len[i])\n        # delE = energy[i] - energy[0]\n        # if delE &lt; MD_energy_lower_cutoff:\n        #     weight.append(cluster_len[i])\n        # elif delE &gt; MD_energy_upper_cutoff:\n        #     weight.append(0.0)\n        # else:\n        #     weight.append(1.0 / math.sqrt(1.0 + (delE - 1.0) ** 2))\n    energy_0 = energy[0]\n    energy_out = torch.tensor([x - energy_0 for x in energy])\n    forces_out = torch.tensor(forces)\n    smiles = mol.to_smiles(isomeric=True, explicit_hydrogens=True, mapped=True)\n    return descent.targets.energy.create_dataset(\n        [\n            {\n                \"smiles\": smiles,\n                \"coords\": coords_out,\n                \"energy\": energy_out,\n                \"forces\": forces_out,\n            }\n        ]\n    )\n</code></pre>"},{"location":"reference/loss_functions/","title":"loss_functions","text":""},{"location":"reference/loss_functions/#bespokefit_smee.loss_functions","title":"loss_functions","text":"<p>Loss functions for tuning the forcefield</p> <p>Functions:</p> <ul> <li> <code>prediction_loss</code>             \u2013              <p>Predict the loss function for a guess forcefield against a dataset.</p> </li> <li> <code>get_loss_closure_fn</code>             \u2013              <p>Return a default closure function</p> </li> <li> <code>predict</code>             \u2013              <p>Predict the relative energies [kcal/mol] and forces [kcal/mol/\u00c5] of a dataset.</p> </li> </ul>"},{"location":"reference/loss_functions/#bespokefit_smee.loss_functions.prediction_loss","title":"prediction_loss","text":"<pre><code>prediction_loss(\n    dataset: Dataset,\n    force_field: TensorForceField,\n    topology: TensorTopology,\n    loss_force_weight: float,\n    device_type: str,\n) -&gt; Tensor\n</code></pre> <p>Predict the loss function for a guess forcefield against a dataset.</p> <p>Args:     dataset: The dataset to predict the energies and forces of.     force_field: The force field to use to predict the energies and forces.     topologies: The topologies of the molecules in the dataset.     loss_force_weight: Weight for the force loss term.     device_type: The device type (e.g., 'cpu' or 'cuda').</p> <p>Returns:     Loss value.</p> Source code in <code>bespokefit_smee/loss_functions.py</code> <pre><code>def prediction_loss(\n    dataset: datasets.Dataset,\n    force_field: smee.TensorForceField,\n    topology: smee.TensorTopology,\n    loss_force_weight: float,\n    device_type: str,\n) -&gt; torch.Tensor:\n    \"\"\"Predict the loss function for a guess forcefield against a dataset.\n\n    Args:\n        dataset: The dataset to predict the energies and forces of.\n        force_field: The force field to use to predict the energies and forces.\n        topologies: The topologies of the molecules in the dataset.\n        loss_force_weight: Weight for the force loss term.\n        device_type: The device type (e.g., 'cpu' or 'cuda').\n\n    Returns:\n        Loss value.\n    \"\"\"\n    energy_ref_all, energy_pred_all, forces_ref_all, forces_pred_all = predict(\n        dataset,\n        force_field,\n        {dataset[0][\"smiles\"]: topology},\n        device_type=device_type,\n        normalize=False,\n    )\n    loss_energy: torch.Tensor = ((energy_ref_all - energy_pred_all) ** 2).mean()\n    loss_forces: torch.Tensor = ((forces_ref_all - forces_pred_all) ** 2).mean()\n    return loss_energy + loss_forces * loss_force_weight\n</code></pre>"},{"location":"reference/loss_functions/#bespokefit_smee.loss_functions.get_loss_closure_fn","title":"get_loss_closure_fn","text":"<pre><code>get_loss_closure_fn(\n    trainable: Trainable,\n    topology: TensorTopology,\n    dataset: Dataset,\n) -&gt; ClosureFn\n</code></pre> <p>Return a default closure function</p> <p>Args:     trainable: The trainable object.     topology: The topology of the system.     dataset: The dataset to use for the loss function.</p> <p>Returns:     A closure function that takes a tensor and returns the loss, gradient (if requested), and hessian (if requested).</p> Source code in <code>bespokefit_smee/loss_functions.py</code> <pre><code>def get_loss_closure_fn(\n    trainable: descent.train.Trainable,\n    topology: smee.TensorTopology,\n    dataset: datasets.Dataset,\n) -&gt; descent.optim.ClosureFn:\n    \"\"\"\n    Return a default closure function\n\n    Args:\n        trainable: The trainable object.\n        topology: The topology of the system.\n        dataset: The dataset to use for the loss function.\n\n    Returns:\n        A closure function that takes a tensor and returns the loss, gradient (if requested), and hessian (if requested).\n    \"\"\"\n\n    def closure_fn(\n        x: torch.Tensor,\n        compute_gradient: bool,\n        compute_hessian: bool,\n    ) -&gt; tuple[torch.Tensor, torch.Tensor | None, torch.Tensor | None]:\n        loss, gradient, hessian = (\n            torch.zeros(size=(1,), device=x.device.type),\n            None,\n            None,\n        )\n\n        def loss_fn(_x: torch.Tensor) -&gt; torch.Tensor:\n            \"\"\"Compute the loss function for the given trainable parameters.\"\"\"\n            ff = trainable.to_force_field(_x)\n            y_ref, y_pred = predict(\n                dataset,\n                ff,\n                {dataset[0][\"smiles\"]: topology},\n                device_type=x.device.type,\n                normalize=False,\n            )[:2]\n            loss: torch.Tensor = ((y_pred - y_ref) ** 2).mean()\n            return loss\n\n        loss += loss_fn(x)\n\n        if compute_hessian:\n            hessian = torch.autograd.functional.hessian(  # type: ignore[no-untyped-call]\n                loss_fn, x, vectorize=True, create_graph=False\n            ).detach()\n        if compute_gradient:\n            (gradient,) = torch.autograd.grad(loss, x, create_graph=False)\n            gradient = gradient.detach()\n\n        return loss, gradient, hessian\n\n    return closure_fn\n</code></pre>"},{"location":"reference/loss_functions/#bespokefit_smee.loss_functions.predict","title":"predict","text":"<pre><code>predict(\n    dataset: Dataset,\n    force_field: TensorForceField,\n    topologies: dict[str, TensorTopology],\n    reference: Literal[\"mean\", \"min\"] = \"mean\",\n    normalize: bool = True,\n    device_type: str = \"cpu\",\n) -&gt; tuple[Tensor, Tensor, Tensor, Tensor]\n</code></pre> <p>Predict the relative energies [kcal/mol] and forces [kcal/mol/\u00c5] of a dataset.</p> <p>Args:     dataset: The dataset to predict the energies and forces of.     force_field: The force field to use to predict the energies and forces.     topologies: The topologies of the molecules in the dataset. Each key should be         a fully indexed SMILES string.     reference: The reference energy to compute the relative energies with respect         to. This should be either the \"mean\" energy of all conformers, or the         energy of the conformer with the lowest reference energy (\"min\").     normalize: Whether to scale the relative energies by <code>1/sqrt(n_confs_i)</code>         and the forces by <code>1/sqrt(n_confs_i * n_atoms_per_conf_i * 3)</code> This         is useful when wanting to compute the MSE per entry.</p> <p>Returns:     The predicted and reference relative energies [kcal/mol] with     <code>shape=(n_confs,)</code>, and predicted and reference forces [kcal/mol/\u00c5] with     <code>shape=(n_confs * n_atoms_per_conf, 3)</code>.</p> Source code in <code>bespokefit_smee/loss_functions.py</code> <pre><code>def predict(\n    dataset: datasets.Dataset,\n    force_field: smee.TensorForceField,\n    topologies: dict[str, smee.TensorTopology],\n    reference: typing.Literal[\"mean\", \"min\"] = \"mean\",\n    normalize: bool = True,\n    device_type: str = \"cpu\",\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Predict the relative energies [kcal/mol] and forces [kcal/mol/\u00c5] of a dataset.\n\n    Args:\n        dataset: The dataset to predict the energies and forces of.\n        force_field: The force field to use to predict the energies and forces.\n        topologies: The topologies of the molecules in the dataset. Each key should be\n            a fully indexed SMILES string.\n        reference: The reference energy to compute the relative energies with respect\n            to. This should be either the \"mean\" energy of all conformers, or the\n            energy of the conformer with the lowest reference energy (\"min\").\n        normalize: Whether to scale the relative energies by ``1/sqrt(n_confs_i)``\n            and the forces by ``1/sqrt(n_confs_i * n_atoms_per_conf_i * 3)`` This\n            is useful when wanting to compute the MSE per entry.\n\n    Returns:\n        The predicted and reference relative energies [kcal/mol] with\n        ``shape=(n_confs,)``, and predicted and reference forces [kcal/mol/\u00c5] with\n        ``shape=(n_confs * n_atoms_per_conf, 3)``.\n    \"\"\"\n    energy_ref_all, energy_pred_all = [], []\n    forces_ref_all, forces_pred_all = [], []\n\n    for entry in dataset:\n        smiles = entry[\"smiles\"]\n\n        energy_ref = entry[\"energy\"].to(device_type)\n        forces_ref = entry[\"forces\"].reshape(len(energy_ref), -1, 3).to(device_type)\n\n        coords_flat = smee.utils.tensor_like(\n            entry[\"coords\"], force_field.potentials[0].parameters\n        )\n\n        coords = (\n            (coords_flat.reshape(len(energy_ref), -1, 3))\n            .to(device_type)\n            .detach()\n            .requires_grad_(True)\n        )\n        topology = topologies[smiles]\n\n        energy_pred = smee.compute_energy(topology, force_field, coords)\n        forces_pred = -torch.autograd.grad(\n            energy_pred.sum(),\n            coords,\n            create_graph=True,\n            retain_graph=True,\n            allow_unused=True,\n        )[0]\n\n        if reference.lower() == \"mean\":\n            energy_ref_0 = energy_ref.mean()\n            energy_pred_0 = energy_pred.mean()\n        elif reference.lower() == \"min\":\n            min_idx = energy_ref.argmin()\n\n            energy_ref_0 = energy_ref[min_idx]\n            energy_pred_0 = energy_pred[min_idx]\n        else:\n            raise NotImplementedError(f\"invalid reference energy {reference}\")\n\n        scale_energy, scale_forces = 1.0, 1.0\n\n        if normalize:\n            scale_energy = 1.0 / torch.sqrt(torch.tensor(energy_pred.numel()))\n            scale_forces = 1.0 / torch.sqrt(torch.tensor(forces_pred.numel()))\n\n        energy_ref_all.append(scale_energy * (energy_ref - energy_ref_0))\n        forces_ref_all.append(scale_forces * forces_ref.reshape(-1, 3))\n\n        energy_pred_all.append(scale_energy * (energy_pred - energy_pred_0))\n        forces_pred_all.append(scale_forces * forces_pred.reshape(-1, 3))\n\n    energy_pred_all_tensor = torch.cat(energy_pred_all)\n    forces_pred_all_tensor = torch.cat(forces_pred_all)\n\n    energy_ref_all_tensor = torch.cat(energy_ref_all)\n    energy_ref_all_tensor = smee.utils.tensor_like(\n        energy_ref_all_tensor, energy_pred_all_tensor\n    )\n\n    forces_ref_all_tensor = torch.cat(forces_ref_all)\n    forces_ref_all_tensor = smee.utils.tensor_like(\n        forces_ref_all_tensor, forces_pred_all_tensor\n    )\n\n    return (\n        energy_ref_all_tensor,\n        energy_pred_all_tensor,\n        forces_ref_all_tensor,\n        forces_pred_all_tensor,\n    )\n</code></pre>"},{"location":"reference/mlp/","title":"mlp","text":""},{"location":"reference/mlp/#bespokefit_smee.mlp","title":"mlp","text":"<p>Functionality for creating Open</p> <p>Functions:</p> <ul> <li> <code>get_egret_1</code>             \u2013              <p>Get the Egret-1 MLPotential from GitHub.</p> </li> <li> <code>get_mlp</code>             \u2013              <p>Get the MLPotential model based on the specified model name.</p> </li> </ul>"},{"location":"reference/mlp/#bespokefit_smee.mlp.get_egret_1","title":"get_egret_1","text":"<pre><code>get_egret_1() -&gt; MLPotential\n</code></pre> <p>Get the Egret-1 MLPotential from GitHub.</p> Source code in <code>bespokefit_smee/mlp.py</code> <pre><code>def get_egret_1() -&gt; MLPotential:\n    \"\"\"Get the Egret-1 MLPotential from GitHub.\"\"\"\n    # Model accessed 24/05/25\n    url = \"https://github.com/rowansci/egret-public/raw/227d6641e6851eb1037d48712462e4ce61c1518f/compiled_models/EGRET_1.model\"\n    tmp_file = tempfile.NamedTemporaryFile(suffix=\".model\", delete=False)\n    tmp_file.close()  # Close so urllib can write to it\n    logger.info(f\"Downloading Egret-1 model from {url}\")\n    urllib.request.urlretrieve(url, filename=tmp_file.name)\n\n    # Register file for deletion at program exit\n    atexit.register(\n        lambda: os.remove(tmp_file.name) if os.path.exists(tmp_file.name) else None\n    )\n\n    return MLPotential(\"mace\", modelPath=tmp_file.name)\n</code></pre>"},{"location":"reference/mlp/#bespokefit_smee.mlp.get_mlp","title":"get_mlp","text":"<pre><code>get_mlp(model: AvailableModels) -&gt; MLPotential\n</code></pre> <p>Get the MLPotential model based on the specified model name.</p> Source code in <code>bespokefit_smee/mlp.py</code> <pre><code>def get_mlp(model: AvailableModels) -&gt; MLPotential:\n    \"\"\"Get the MLPotential model based on the specified model name.\"\"\"\n\n    if model not in get_args(AvailableModels):\n        raise ValueError(\n            f\"Invalid model name: {model}. Available models are: {get_args(AvailableModels)}\"\n        )\n\n    if model in aimnet2._AVAILABLE_MODELS:\n        # Ensure AIMNet2 models registered\n        aimnet2._register_aimnet2_potentials()\n\n    if model == \"egret-1\":\n        return get_egret_1()\n    else:\n        return MLPotential(model)\n</code></pre>"},{"location":"reference/parameterizer/","title":"parameterizer","text":""},{"location":"reference/parameterizer/#bespokefit_smee.parameterizer","title":"parameterizer","text":"<p>PARAMETERIZE:</p> <p>force-field parameterization functions</p> <p>Functions:</p> <ul> <li> <code>convert_to_smirnoff</code>             \u2013              <p>Convert a tensor force field that contains bespoke valence parameters to</p> </li> <li> <code>build_parameters</code>             \u2013              <p>Prepare a Trainable object that contains  a force field with</p> </li> <li> <code>expand_torsions</code>             \u2013              <p>Expand the torsion potential to include K0-4 for proper torsions</p> </li> <li> <code>modSeminario</code>             \u2013              <p>Generate modified Seminario parameters for the bond and angle terms in the</p> </li> <li> <code>unit_normal_vector</code>             \u2013              <p>Return a unit vector perpendicular to the two input vectors</p> </li> <li> <code>modSem_projection</code>             \u2013              <p>Return a spring constant projected out of a partial hessian onto a unit vector</p> </li> <li> <code>linearize_harmonics</code>             \u2013              <p>Linearize the harmonic potential parameters in the forcefield for more robust optimization</p> </li> <li> <code>linearize_propertorsions</code>             \u2013              <p>Linearize the proper torsion parameters in the forcefield for more robust optimization</p> </li> <li> <code>linearize_impropertorsions</code>             \u2013              <p>Linearize the improper torsion parameters in the forcefield for more robust optimization</p> </li> </ul>"},{"location":"reference/parameterizer/#bespokefit_smee.parameterizer.convert_to_smirnoff","title":"convert_to_smirnoff","text":"<pre><code>convert_to_smirnoff(\n    ff: TensorForceField, base: ForceField | None = None\n) -&gt; ForceField\n</code></pre> <p>Convert a tensor force field that contains bespoke valence parameters to SMIRNOFF format. Args:     ff: The force field containing the bespoke valence terms.     base: The (optional) original SMIRNOFF force field to add the bespoke         parameters to. If no specified, a force field containing only the bespoke         parameters will be returned. Returns:     A SMIRNOFF force field containing the valence terms of the input force field.</p> Source code in <code>bespokefit_smee/parameterizer.py</code> <pre><code>def convert_to_smirnoff(\n    ff: smee.TensorForceField, base: openff.toolkit.ForceField | None = None\n) -&gt; openff.toolkit.ForceField:\n    \"\"\"Convert a tensor force field that *contains bespoke valence parameters* to\n    SMIRNOFF format.\n    Args:\n        ff: The force field containing the bespoke valence terms.\n        base: The (optional) original SMIRNOFF force field to add the bespoke\n            parameters to. If no specified, a force field containing only the bespoke\n            parameters will be returned.\n    Returns:\n        A SMIRNOFF force field containing the valence terms of the input force field.\n    \"\"\"\n    ff_smirnoff = openff.toolkit.ForceField() if base is None else copy.deepcopy(base)\n\n    for potential in ff.potentials:\n        if potential.type in {\"Bonds\", \"Angles\", \"ProperTorsions\", \"ImproperTorsions\"}:\n            assert potential.attribute_cols is None\n            parameters_by_smarts: dict[str, dict[int | None, torch.Tensor]] = (\n                collections.defaultdict(dict)\n            )\n            for parameter, parameter_key in zip(\n                potential.parameters, potential.parameter_keys, strict=True\n            ):\n                assert parameter_key.mult not in parameters_by_smarts[parameter_key.id]\n                parameters_by_smarts[parameter_key.id][parameter_key.mult] = parameter\n            handler = ff_smirnoff.get_parameter_handler(potential.type)\n            for smarts, parameters_by_mult in parameters_by_smarts.items():\n                mults = {*parameters_by_mult}\n                if None in mults and len(mults) &gt; 1:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                if None not in mults and mults != {*range(len(mults))}:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                counter = len(handler.parameters) + 1\n                parameter_id = f\"{potential.type[0].lower()}-bespoke-{counter}\"\n                parameter_dict: dict[str, str | Quantity] = {\n                    \"smirks\": smarts,\n                    \"id\": parameter_id,\n                }\n                parameter_dict.update(\n                    {\n                        (col if mult is None else f\"{col}{mult + 1}\"): float(\n                            parameter[col_idx]\n                        )\n                        * potential.parameter_units[col_idx]\n                        for mult, parameter in parameters_by_mult.items()\n                        for col_idx, col in enumerate(potential.parameter_cols)\n                    }\n                )\n                handler.add_parameter(parameter_dict)\n        elif potential.type == \"LinearBonds\":\n            assert potential.attribute_cols is None\n            parameters_by_smarts = collections.defaultdict(dict)\n            new_params = []\n            for param in potential.parameters:\n                k1 = param[0].item()\n                k2 = param[1].item()\n                b1 = param[2].item()\n                b2 = param[3].item()\n                k = k1 + k2\n                b = (k1 * b1 + k2 * b2) / k\n                dt = param.dtype\n                new_params.append([k, b])\n            reconstructed_param = torch.tensor(new_params, dtype=dt)\n            reconstructed_units = (_KCAL_PER_MOL_ANGSQ, _ANGSTROM)\n            reconstructed_cols = (\"k\", \"length\")\n            for parameter, parameter_key in zip(\n                reconstructed_param, potential.parameter_keys, strict=True\n            ):\n                assert parameter_key.mult not in parameters_by_smarts[parameter_key.id]\n                parameters_by_smarts[parameter_key.id][parameter_key.mult] = parameter\n            handler = ff_smirnoff.get_parameter_handler(\"Bonds\")\n            for smarts, parameters_by_mult in parameters_by_smarts.items():\n                mults = {*parameters_by_mult}\n                if None in mults and len(mults) &gt; 1:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                if None not in mults and mults != {*range(len(mults))}:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                counter = len(handler.parameters) + 1\n                parameter_id = f\"{potential.type[0].lower()}-bespoke-{counter}\"\n                parameter_dict = {\"smirks\": smarts, \"id\": parameter_id}\n                parameter_dict.update(\n                    {\n                        (col if mult is None else f\"{col}{mult + 1}\"): float(\n                            parameter[col_idx]\n                        )\n                        * reconstructed_units[col_idx]\n                        for mult, parameter in parameters_by_mult.items()\n                        for col_idx, col in enumerate(reconstructed_cols)\n                    }\n                )\n                handler.add_parameter(parameter_dict)\n        elif potential.type == \"LinearAngles\":\n            assert potential.attribute_cols is None\n            parameters_by_smarts = collections.defaultdict(dict)\n            new_params = []\n            for param in potential.parameters:\n                k1 = param[0].item()\n                k2 = param[1].item()\n                a1 = param[2].item()\n                a2 = param[3].item()\n                k = k1 + k2\n                # Set k and angle to 0 if very close\n                a = (k1 * a1 + k2 * a2) / k\n                if a &lt; 0 or a &gt; math.pi:\n                    breakpoint()\n                dt = param.dtype\n                new_params.append([k, a])\n            reconstructed_param = torch.tensor(new_params, dtype=dt)\n            reconstructed_units = (_KCAL_PER_MOL_RADSQ, _RADIANS)\n            reconstructed_cols = (\"k\", \"angle\")\n            for parameter, parameter_key in zip(\n                reconstructed_param, potential.parameter_keys, strict=True\n            ):\n                assert parameter_key.mult not in parameters_by_smarts[parameter_key.id]\n                parameters_by_smarts[parameter_key.id][parameter_key.mult] = parameter\n            handler = ff_smirnoff.get_parameter_handler(\"Angles\")\n            for smarts, parameters_by_mult in parameters_by_smarts.items():\n                mults = {*parameters_by_mult}\n                if None in mults and len(mults) &gt; 1:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                if None not in mults and mults != {*range(len(mults))}:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                counter = len(handler.parameters) + 1\n                parameter_id = f\"{potential.type[0].lower()}-bespoke-{counter}\"\n                parameter_dict = {\"smirks\": smarts, \"id\": parameter_id}\n                parameter_dict.update(\n                    {\n                        (col if mult is None else f\"{col}{mult + 1}\"): float(\n                            parameter[col_idx]\n                        )\n                        * reconstructed_units[col_idx]\n                        for mult, parameter in parameters_by_mult.items()\n                        for col_idx, col in enumerate(reconstructed_cols)\n                    }\n                )\n                handler.add_parameter(parameter_dict)\n        elif potential.type == \"LinearProperTorsions\":\n            assert potential.attribute_cols is None\n            parameters_by_smarts = collections.defaultdict(dict)\n            new_params = []\n            for param in potential.parameters:\n                k1 = param[0].item()\n                k2 = param[1].item()\n                periodicity = param[2].item()\n                # Params 3 and 4 are phase1 and phase2\n                idivf = param[5].item()\n                k = k1 + k2\n                if k == 0.0:\n                    phase = 0.0\n                else:\n                    phase = math.acos((k1 - k2) / k)\n                dt = param.dtype\n                new_params.append([k, periodicity, phase, idivf])\n            reconstructed_param = torch.tensor(new_params, dtype=dt)\n            reconstructed_torsion_units = (\n                _KCAL_PER_MOL,\n                _UNITLESS,\n                _RADIANS,\n                _UNITLESS,\n            )\n            reconstructed_torsion_cols = (\"k\", \"periodicity\", \"phase\", \"idivf\")\n            for parameter, parameter_key in zip(\n                reconstructed_param, potential.parameter_keys, strict=True\n            ):\n                assert parameter_key.mult not in parameters_by_smarts[parameter_key.id]\n                parameters_by_smarts[parameter_key.id][parameter_key.mult] = parameter\n            handler = ff_smirnoff.get_parameter_handler(\"ProperTorsions\")\n            for smarts, parameters_by_mult in parameters_by_smarts.items():\n                mults = {*parameters_by_mult}\n                if None in mults and len(mults) &gt; 1:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                if None not in mults and mults != {*range(len(mults))}:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                counter = len(handler.parameters) + 1\n                parameter_id = f\"{potential.type[0].lower()}-bespoke-{counter}\"\n                parameter_dict = {\"smirks\": smarts, \"id\": parameter_id}\n                parameter_dict.update(\n                    {\n                        (col if mult is None else f\"{col}{mult + 1}\"): float(\n                            parameter[col_idx]\n                        )\n                        * reconstructed_torsion_units[col_idx]\n                        for mult, parameter in parameters_by_mult.items()\n                        for col_idx, col in enumerate(reconstructed_torsion_cols)\n                    }\n                )\n                handler.add_parameter(parameter_dict)\n        elif potential.type == \"LinearImproperTorsions\":\n            assert potential.attribute_cols is None\n            parameters_by_smarts = collections.defaultdict(dict)\n            new_params = []\n            for param in potential.parameters:\n                k1 = param[0].item()\n                k2 = param[1].item()\n                periodicity = param[2].item()\n                # Params 3 and 4 are phase1 and phase2\n                idivf = param[5].item()\n                k = k1 + k2\n                if k == 0.0:\n                    phase = 0.0\n                else:\n                    phase = math.acos((k1 - k2) / k)\n                #                    phase = math.acos((k1 * math.cos(phase1) + k2 * math.cos(phase2))/k)\n                dt = param.dtype\n                new_params.append([k, periodicity, phase, idivf])\n            reconstructed_param = torch.tensor(new_params, dtype=dt)\n            reconstructed_torsion_units = (\n                _KCAL_PER_MOL,\n                _UNITLESS,\n                _RADIANS,\n                _UNITLESS,\n            )\n            reconstructed_torsion_cols = (\"k\", \"periodicity\", \"phase\", \"idivf\")\n            for parameter, parameter_key in zip(\n                reconstructed_param, potential.parameter_keys, strict=True\n            ):\n                assert parameter_key.mult not in parameters_by_smarts[parameter_key.id]\n                parameters_by_smarts[parameter_key.id][parameter_key.mult] = parameter\n            handler = ff_smirnoff.get_parameter_handler(\"ImproperTorsions\")\n            for smarts, parameters_by_mult in parameters_by_smarts.items():\n                mults = {*parameters_by_mult}\n                if None in mults and len(mults) &gt; 1:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                if None not in mults and mults != {*range(len(mults))}:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                counter = len(handler.parameters) + 1\n                parameter_id = f\"{potential.type[0].lower()}-bespoke-{counter}\"\n                parameter_dict = {\"smirks\": smarts, \"id\": parameter_id}\n                parameter_dict.update(\n                    {\n                        (col if mult is None else f\"{col}{mult + 1}\"): float(\n                            parameter[col_idx]\n                        )\n                        * reconstructed_torsion_units[col_idx]\n                        for mult, parameter in parameters_by_mult.items()\n                        for col_idx, col in enumerate(reconstructed_torsion_cols)\n                    }\n                )\n                handler.add_parameter(parameter_dict)\n\n    return ff_smirnoff\n</code></pre>"},{"location":"reference/parameterizer/#bespokefit_smee.parameterizer.build_parameters","title":"build_parameters","text":"<pre><code>build_parameters(\n    mol: Molecule,\n    off: ForceField,\n    ML_path: str,\n    linear_harmonics: bool,\n    linear_torsions: bool,\n    modSem: bool,\n    modSem_finite_step: float,\n    modSem_vib_scaling: float,\n    modSem_tolerance: float,\n    device_type: TorchDevice = \"cuda\",\n) -&gt; tuple[TensorForceField, Trainable, TensorTopology]\n</code></pre> <p>Prepare a Trainable object that contains  a force field with unique parameters for each topologically symmetric term of a molecule. Args:     mol: The molecule to prepare bespoke parameters for.     off: The base force field to copy the parameters from.     ML_path: Path to the MLMD potential used to evalutate the hessian - if used     linear_harmonics: boolean indicating whether to use linearized harmonic potentials     linear_torsions: boolean indicating whether to use linearized torsion potentials     modSem: boolean indicating whether to use the moedified Seminario method to initialize the force-field     modSem_finite_step: finite step used in evaluating the hessian - if used     modSem_vib_scaling: scaling parameter for the modSem parameters     modSem_tolerance: Tolerance for the geometric minimization before the hessian evaluation - if used</p> <p>Returns:     The prepared Traninable object with a smee force_field and topology ready for fitting.</p> Source code in <code>bespokefit_smee/parameterizer.py</code> <pre><code>def build_parameters(\n    mol: openff.toolkit.Molecule,\n    off: openff.toolkit.ForceField,\n    ML_path: str,\n    linear_harmonics: bool,\n    linear_torsions: bool,\n    modSem: bool,\n    modSem_finite_step: float,\n    modSem_vib_scaling: float,\n    modSem_tolerance: float,\n    device_type: TorchDevice = \"cuda\",\n) -&gt; tuple[smee.TensorForceField, Trainable, smee.TensorTopology]:\n    \"\"\"Prepare a Trainable object that contains  a force field with\n    unique parameters for each topologically symmetric term of a molecule.\n    Args:\n        mol: The molecule to prepare bespoke parameters for.\n        off: The base force field to copy the parameters from.\n        ML_path: Path to the MLMD potential used to evalutate the hessian - if used\n        linear_harmonics: boolean indicating whether to use linearized harmonic potentials\n        linear_torsions: boolean indicating whether to use linearized torsion potentials\n        modSem: boolean indicating whether to use the moedified Seminario method to initialize the force-field\n        modSem_finite_step: finite step used in evaluating the hessian - if used\n        modSem_vib_scaling: scaling parameter for the modSem parameters\n        modSem_tolerance: Tolerance for the geometric minimization before the hessian evaluation - if used\n\n    Returns:\n        The prepared Traninable object with a smee force_field and topology ready for fitting.\n    \"\"\"\n    del off[\"Constraints\"].parameters[\"[#1:1]-[*:2]\"]\n    force_field, [topology] = smee.converters.convert_interchange(\n        openff.interchange.Interchange.from_smirnoff(\n            expand_torsions(off), mol.to_topology()\n        )\n    )\n\n    # Move the force field and topology to the requested device\n    force_field = force_field.to(device_type)\n    topology = topology.to(device_type)\n\n    symmetries = list(Chem.CanonicalRankAtoms(mol.to_rdkit(), breakTies=False))\n    if topology.n_v_sites != 0:\n        raise NotImplementedError(\"virtual sites are not supported yet.\")\n    for potential in force_field.potentials:\n        parameter_map = topology.parameters[potential.type]\n        if isinstance(parameter_map, smee.NonbondedParameterMap):\n            continue\n        _prepare_potential(\n            mol, symmetries, potential, parameter_map\n        )  ### ??? is it re-ordering the atoms and bonds?\n    if modSem:\n        force_field = modSeminario(\n            mol,\n            topology,\n            off,\n            ML_path,\n            force_field,\n            modSem_finite_step,\n            modSem_vib_scaling,\n            modSem_tolerance,\n        )\n    # Parameter scales obtained from trained force field - but only for linearised bonds and\n    # angles and unlinearised harmonics.\n    if linear_harmonics:\n        topology.parameters[\"LinearBonds\"] = copy.deepcopy(topology.parameters[\"Bonds\"])\n        topology.parameters[\"LinearAngles\"] = copy.deepcopy(\n            topology.parameters[\"Angles\"]\n        )\n        force_field = linearize_harmonics(force_field, device_type)\n        parameter_list = {\n            \"LinearBonds\": ParameterConfig(\n                cols=[\"k1\", \"k2\"],\n                scales={\"k1\": 0.0024, \"k2\": 0.0024},\n                limits={\"k1\": (None, None), \"k2\": (None, None)},\n            ),\n            \"LinearAngles\": ParameterConfig(\n                cols=[\"k1\", \"k2\"],\n                scales={\"k1\": 0.0207, \"k2\": 0.0207},\n                limits={\"k1\": (None, None), \"k2\": (None, None)},\n            ),\n        }\n    else:\n        parameter_list = {\n            \"Bonds\": ParameterConfig(\n                cols=[\"k\", \"length\"],\n                scales={\"k\": 1.0, \"length\": 1.0},\n                limits={\"k\": (0.0, None), \"length\": (0.0, None)},\n            ),\n            \"Angles\": ParameterConfig(\n                cols=[\"k\", \"angle\"],\n                scales={\"k\": 1.0, \"angle\": 1.0},\n                limits={\"k\": (0.0, None), \"angle\": (0.0, math.pi)},\n            ),\n        }\n    for potential in force_field.potentials:\n        if potential.type == \"ProperTorsions\":\n            if linear_torsions:\n                topology.parameters[\"LinearProperTorsions\"] = copy.deepcopy(\n                    topology.parameters[\"ProperTorsions\"]\n                )\n                force_field = linearize_propertorsions(force_field, device_type)\n                parameter_list.update(\n                    {\n                        \"LinearProperTorsions\": ParameterConfig(\n                            cols=[\"k1\", \"k2\"],\n                            scales={\"k1\": 100.0, \"k2\": 100.0},\n                            limits={\"k1\": (0, None), \"k2\": (0, None)},\n                        )\n                    }\n                )\n            else:\n                parameter_list.update(\n                    {\n                        \"ProperTorsions\": ParameterConfig(\n                            cols=[\"k\"],\n                            scales={\n                                \"k\": 0.3252,\n                            },\n                            limits={\"k\": (None, None)},\n                        ),\n                    }\n                )\n        elif potential.type == \"ImproperTorsions\":\n            if linear_torsions:\n                topology.parameters[\"LinearImproperTorsions\"] = copy.deepcopy(\n                    topology.parameters[\"ImproperTorsions\"]\n                )\n                force_field = linearize_impropertorsions(force_field, device_type)\n                parameter_list.update(\n                    {\n                        \"LinearImproperTorsions\": ParameterConfig(\n                            cols=[\"k1\", \"k2\"],\n                            scales={\"k1\": 100.0, \"k2\": 100.0},\n                            limits={\"k1\": (0, None), \"k2\": (0, None)},\n                        ),\n                    }\n                )\n            else:\n                parameter_list.update(\n                    {\n                        \"ImproperTorsions\": ParameterConfig(\n                            cols=[\"k\"],\n                            scales={\n                                \"k\": 0.1647,\n                            },\n                            limits={\"k\": (None, None)},\n                        ),\n                    }\n                )\n\n    return (\n        copy.deepcopy(force_field),\n        Trainable(force_field, parameter_list, {}),\n        topology,\n    )\n</code></pre>"},{"location":"reference/parameterizer/#bespokefit_smee.parameterizer.expand_torsions","title":"expand_torsions","text":"<pre><code>expand_torsions(ff: ForceField) -&gt; ForceField\n</code></pre> <p>Expand the torsion potential to include K0-4 for proper torsions</p> Source code in <code>bespokefit_smee/parameterizer.py</code> <pre><code>def expand_torsions(ff: openff.toolkit.ForceField) -&gt; openff.toolkit.ForceField:\n    \"\"\"Expand the torsion potential to include K0-4 for proper torsions\"\"\"\n    ff_copy = copy.deepcopy(ff)\n    torsion_handler = ff_copy.get_parameter_handler(\"ProperTorsions\")\n    for parameter in torsion_handler:\n        # set the defaults\n        parameter.idivf = [1.0] * 4\n        default_k = [0 * _KCAL_PER_MOL] * 4\n        default_phase = [0 * _RADIANS] * 4\n        default_p = [1, 2, 3, 4]\n        # update the existing k values for the correct phase and p\n        for i, p in enumerate(parameter.periodicity):\n            try:\n                default_k[p - 1] = parameter.k[i]\n                default_phase[p - 1] = parameter.phase[i]\n            except IndexError:\n                continue\n        # update with new parameters\n        parameter.k = default_k\n        parameter.phase = default_phase\n        parameter.periodicity = default_p\n    return ff_copy\n</code></pre>"},{"location":"reference/parameterizer/#bespokefit_smee.parameterizer.modSeminario","title":"modSeminario","text":"<pre><code>modSeminario(\n    mol: Molecule,\n    top: TensorTopology,\n    off: ForceField,\n    ML_path: str,\n    sff: TensorForceField,\n    finite_step: float,\n    vib_scaling: float,\n    minimize_tol: float,\n) -&gt; TensorForceField\n</code></pre> <p>Generate modified Seminario parameters for the bond and angle terms in the force-field. see doi: 10.1021/acs.jctc.7b00785</p> Source code in <code>bespokefit_smee/parameterizer.py</code> <pre><code>def modSeminario(\n    mol: openff.toolkit.Molecule,\n    top: smee.TensorTopology,\n    off: openff.toolkit.ForceField,\n    ML_path: str,\n    sff: smee.TensorForceField,\n    finite_step: float,\n    vib_scaling: float,\n    minimize_tol: float,\n) -&gt; smee.TensorForceField:\n    \"\"\"Generate modified Seminario parameters for the bond and angle terms in the\n    force-field. see doi: 10.1021/acs.jctc.7b00785\n    \"\"\"\n    from openmm import LangevinMiddleIntegrator\n    from openmm.app.simulation import Simulation\n    from openmmml import MLPotential\n\n    from .writers import get_potential_comparison\n\n    #   set up an MD sim with the ML potential\n    molecule = copy.deepcopy(mol)\n    molecule.generate_conformers(n_conformers=1)\n    interchange = openff.interchange.Interchange.from_smirnoff(\n        off, openff.toolkit.Topology.from_molecules(molecule)\n    )\n    integrator = LangevinMiddleIntegrator(0 * _OMM_KELVIN, 1 / _OMM_PS, 0.01 * _OMM_PS)\n    potential = MLPotential(ML_path)\n    with open(\"/dev/null\", \"w\") as f:\n        with redirect_stdout(f):\n            system = potential.createSystem(interchange.to_openmm_topology())\n    simulation = Simulation(interchange.topology, system, integrator)\n    #   calculate the ground-state geometry and energy\n    interchange.positions = molecule.conformers[0]\n    simulation.context.setPositions(interchange.positions.to_openmm())\n    simulation.minimizeEnergy(\n        maxIterations=0, tolerance=minimize_tol * _OMM_KCAL_PER_MOL_ANGS\n    )\n    position = simulation.context.getState(getPositions=True).getPositions(asNumpy=True)\n    crd0 = position.value_in_unit(_OMM_NM).reshape(3 * molecule.n_atoms)\n    #   extract bond info from the smee tensor\n    bonds_obj = cast(smee.ValenceParameterMap, copy.deepcopy(top.parameters[\"Bonds\"]))\n    n_bonds = len(bonds_obj.assignment_matrix.indices()[0].detach().flatten().tolist())\n    n_bond_types = (\n        max(bonds_obj.assignment_matrix.indices()[-1].detach().flatten().tolist()) + 1\n    )\n    bond_types = [\n        [\n            i\n            for i, x in enumerate(bonds_obj.assignment_matrix.indices()[-1].tolist())\n            if x == j\n        ]\n        for j in range(n_bond_types)\n    ]\n    bond_indxs = bonds_obj.particle_idxs.tolist()\n    #   extract angle info from the smee tensor\n    angles_obj = cast(smee.ValenceParameterMap, copy.deepcopy(top.parameters[\"Angles\"]))\n    n_angles = len(\n        angles_obj.assignment_matrix.indices()[0].detach().flatten().tolist()\n    )\n    n_angle_types = (\n        max(angles_obj.assignment_matrix.indices()[-1].detach().flatten().tolist()) + 1\n    )\n    angle_types = [\n        [\n            i\n            for i, x in enumerate(angles_obj.assignment_matrix.indices()[-1].tolist())\n            if x == j\n        ]\n        for j in range(n_angle_types)\n    ]\n    angle_indxs = angles_obj.particle_idxs.tolist()\n    #   calculate hessian elements with finite difference, ignoring the diagonal and all below\n    hessian = np.zeros((3 * molecule.n_atoms, 3 * molecule.n_atoms))\n    for i in tqdm(\n        range(n_bonds), leave=False, colour=\"green\", desc=\"Generating Hessian Fragments\"\n    ):\n        i1, i2 = bond_indxs[i][0] * 3, bond_indxs[i][1] * 3\n        for j1 in range(i1, i1 + 3):\n            crd = crd0\n            crd[j1] += finite_step\n            simulation.context.setPositions(\n                crd.reshape(molecule.n_atoms, 3)\n            )  # coords +\n            f1 = (\n                simulation.context.getState(getForces=True)\n                .getForces(asNumpy=True)\n                .value_in_unit(_OMM_KCAL_PER_MOL_ANGS)\n            )\n            dEp = -f1[i2 // 3]\n            crd[j1] -= 2 * finite_step\n            simulation.context.setPositions(\n                crd.reshape(molecule.n_atoms, 3)\n            )  # coords -\n            f1 = (\n                simulation.context.getState(getForces=True)\n                .getForces(asNumpy=True)\n                .value_in_unit(_OMM_KCAL_PER_MOL_ANGS)\n            )\n            dEm = -f1[i2 // 3]\n            hessian[j1, range(i2, i2 + 3)] = (dEp - dEm) / (2 * finite_step)\n    #   calculate mod-seminario force constants along the bonds and group by bond-type, as given in the smee tensors\n    bond_k, bond_l = [], []\n    for j in range(n_bond_types):\n        k_sum, l_sum = 0.0, 0.0\n        for i in bond_types[j]:\n            iA, iB = bond_indxs[i][0], bond_indxs[i][1]\n            jA, jB = iA * 3, iB * 3\n            b = (\n                position.value_in_unit(_OMM_ANGS)[iA]\n                - position.value_in_unit(_OMM_ANGS)[iB]\n            )\n            norm_b = np.linalg.norm(b)\n            k_sum += modSem_projection(-hessian[jA : jA + 3, jB : jB + 3], b / norm_b)\n            l_sum += float(norm_b)\n        bond_k.append(k_sum * vib_scaling**2 * 0.1 / len(bond_types[j]))\n        bond_l.append(l_sum / len(bond_types[j]))\n    #   calculate mod-seminario force constants along around the angles and group by angle-type, as given in the smee tensors\n    angle_k, angle_t = [], []\n    for j in range(n_angle_types):\n        k_sum, t_sum = 0.0, 0.0\n        for i in angle_types[j]:\n            iA, iB, iC = angle_indxs[i][0], angle_indxs[i][1], angle_indxs[i][2]\n            jA, jB, jC = iA * 3, iB * 3, iC * 3\n            bAB = (\n                position.value_in_unit(_OMM_ANGS)[iA]\n                - position.value_in_unit(_OMM_ANGS)[iB]\n            )\n            bCB = (\n                position.value_in_unit(_OMM_ANGS)[iC]\n                - position.value_in_unit(_OMM_ANGS)[iB]\n            )\n            if iA &gt; iB:\n                HAB = -hessian[jB : jB + 3, jA : jA + 3]\n            else:\n                HAB = -hessian[jA : jA + 3, jB : jB + 3]\n            if iC &gt; iB:\n                HCB = -hessian[jB : jB + 3, jC : jC + 3]\n            else:\n                HCB = -hessian[jC : jC + 3, jB : jB + 3]\n            lAB, lCB = np.linalg.norm(bAB), np.linalg.norm(bCB)\n            uAB, uCB = bAB / lAB, bCB / lCB\n            uN = unit_normal_vector(uAB, uCB)\n            uPA, uPC = unit_normal_vector(uN, uAB), unit_normal_vector(uCB, uN)\n            kPA, kPC = modSem_projection(HAB, uPA), modSem_projection(HCB, uPC)\n            fixA, fixC = 0.0, 0.0\n            NfA, NfC = 0.0, 0.0\n            for jj in range(n_angles):\n                iiA, iiB, iiC = (\n                    angle_indxs[jj][0],\n                    angle_indxs[jj][1],\n                    angle_indxs[jj][2],\n                )\n                if iiB == iB &amp; jj != i:\n                    if iiA == iA:\n                        bCBp = (\n                            position.value_in_unit(_OMM_ANGS)[iiC]\n                            - position.value_in_unit(_OMM_ANGS)[iiB]\n                        )\n                        uPAp = unit_normal_vector(\n                            unit_normal_vector(uAB, bCBp / np.linalg.norm(bCBp)), uAB\n                        )\n                        fixA += np.dot(uPA, uPAp) ** 2\n                        NfA += 1\n                    elif iiC == iC:\n                        bABp = (\n                            position.value_in_unit(_OMM_ANGS)[iiA]\n                            - position.value_in_unit(_OMM_ANGS)[iiB]\n                        )\n                        uPCp = unit_normal_vector(\n                            unit_normal_vector(uCB, bABp / np.linalg.norm(bABp)), uCB\n                        )\n                        fixC += np.dot(uPC, uPCp) ** 2\n                        NfC += 1\n            if NfA &gt; 0:\n                fixA = fixA / NfA\n            if NfC &gt; 0:\n                fixC = fixC / NfC\n            k_sum += float(\n                1 / (((1 + fixA) / (lAB**2 * kPA)) + ((1 + fixC) / (lCB**2 * kPC)))\n            )\n            t_sum += np.arccos(np.dot(uAB, uCB))\n        angle_k.append(k_sum * vib_scaling**2 * 0.1 / len(angle_types[j]))\n        angle_t.append(t_sum / len(angle_types[j]))\n    #   put the new constants into the force-field object and report!\n    sff_out = copy.deepcopy(sff)\n    sff_out.potentials_by_type[\"Bonds\"].parameters = torch.tensor(\n        [[bond_k[j], bond_l[j]] for j in range(n_bond_types)]\n    )\n    sff_out.potentials_by_type[\"Angles\"].parameters = torch.tensor(\n        [[angle_k[j], angle_t[j]] for j in range(n_angle_types)]\n    )\n    bond_potential_comparison = get_potential_comparison(\n        sff.potentials_by_type[\"Bonds\"],\n        sff_out.potentials_by_type[\"Bonds\"],\n    )\n    angle_potential_comparison = get_potential_comparison(\n        sff.potentials_by_type[\"Angles\"],\n        sff_out.potentials_by_type[\"Angles\"],\n    )\n\n    logger.info(\n        \"Modified Seminario Summary:\"\n        f\"{bond_potential_comparison}\"\n        f\"{angle_potential_comparison}\"\n    )\n\n    return sff_out\n</code></pre>"},{"location":"reference/parameterizer/#bespokefit_smee.parameterizer.unit_normal_vector","title":"unit_normal_vector","text":"<pre><code>unit_normal_vector(\n    u1: NDArray[float64], u2: NDArray[float64]\n) -&gt; NDArray[float64]\n</code></pre> <p>Return a unit vector perpendicular to the two input vectors</p> Source code in <code>bespokefit_smee/parameterizer.py</code> <pre><code>def unit_normal_vector(\n    u1: npt.NDArray[np.float64], u2: npt.NDArray[np.float64]\n) -&gt; npt.NDArray[np.float64]:\n    \"\"\"Return a unit vector perpendicular to the two input vectors\"\"\"\n    cross = np.cross(u1, u2)\n    return cross / np.linalg.norm(cross)\n</code></pre>"},{"location":"reference/parameterizer/#bespokefit_smee.parameterizer.modSem_projection","title":"modSem_projection","text":"<pre><code>modSem_projection(\n    parhess: NDArray[float64], unit_vector: NDArray[float64]\n) -&gt; float\n</code></pre> <p>Return a spring constant projected out of a partial hessian onto a unit vector</p> Source code in <code>bespokefit_smee/parameterizer.py</code> <pre><code>def modSem_projection(\n    parhess: npt.NDArray[np.float64], unit_vector: npt.NDArray[np.float64]\n) -&gt; float:\n    \"\"\"Return a spring constant projected out of a partial hessian onto a unit vector\"\"\"\n    vals, vecs = np.linalg.eig(parhess)\n    kab1 = sum(abs(np.dot(unit_vector, vecs[:, i])) * vals[i] for i in range(3)).real\n    kba1 = sum(\n        abs(np.dot(unit_vector[::-1], vecs[:, i])) * vals[i] for i in range(3)\n    ).real\n    vals, vecs = np.linalg.eig(parhess.transpose())\n    kab2 = sum(abs(np.dot(unit_vector, vecs[:, i])) * vals[i] for i in range(3)).real\n    kba2 = sum(\n        abs(np.dot(unit_vector[::-1], vecs[:, i])) * vals[i] for i in range(3)\n    ).real\n    return float(0.25 * (kab1 + kba1 + kab2 + kba2))\n</code></pre>"},{"location":"reference/parameterizer/#bespokefit_smee.parameterizer.linearize_harmonics","title":"linearize_harmonics","text":"<pre><code>linearize_harmonics(\n    ff: TensorForceField, device_type: str\n) -&gt; TensorForceField\n</code></pre> <p>Linearize the harmonic potential parameters in the forcefield for more robust optimization</p> Source code in <code>bespokefit_smee/parameterizer.py</code> <pre><code>def linearize_harmonics(\n    ff: smee.TensorForceField, device_type: str\n) -&gt; smee.TensorForceField:\n    \"\"\"Linearize the harmonic potential parameters in the forcefield for more robust optimization\"\"\"\n    ff_copy = copy.deepcopy(ff)\n    ff_copy.potentials = []\n    for potential in ff.potentials:\n        if potential.type in {\"Bonds\"}:\n            new_potential = copy.deepcopy(potential)\n            new_potential.type = \"LinearBonds\"\n            new_potential.fn = \"(k1+k2)/2*(r-(k1*length1+k2*length2)/(k1+k2))**2\"\n            new_potential.parameter_cols = (\"k1\", \"k2\", \"b1\", \"b2\")\n            new_params = []\n            for param in potential.parameters:\n                k = param[0].item()\n                b = param[1].item()\n                dt = param.dtype\n                b1 = b * 0.9\n                b2 = b * 1.1\n                d = b2 - b1\n                k1 = k * (b2 - b) / d\n                k2 = k * (b - b1) / d\n                new_params.append([k1, k2, b1, b2])\n            new_potential.parameters = torch.tensor(\n                new_params, dtype=dt, requires_grad=False, device=device_type\n            )\n            new_potential.parameter_units = (\n                _KCAL_PER_MOL_ANGSQ,\n                _KCAL_PER_MOL_ANGSQ,\n                _ANGSTROM,\n                _ANGSTROM,\n            )\n            ff_copy.potentials.append(new_potential)\n        elif potential.type in {\"Angles\"}:\n            new_potential = copy.deepcopy(potential)\n            new_potential.type = \"LinearAngles\"\n            new_potential.fn = \"(k1+k2)/2*(r-(k1*angle1+k2*angle2)/(k1+k2))**2\"\n            new_potential.parameter_cols = (\"k1\", \"k2\", \"angle1\", \"angle2\")\n            new_params = []\n            for param in potential.parameters:\n                k = param[0].item()\n                a = param[1].item()\n                dt = param.dtype\n                a1 = a * 0.9\n                a2 = a * 1.1\n                d = a2 - a1\n                k1 = k * (a2 - a) / d\n                k2 = k * (a - a1) / d\n                new_params.append([k1, k2, a1, a2])\n            new_potential.parameters = torch.tensor(\n                new_params, dtype=dt, requires_grad=False, device=device_type\n            )\n            new_potential.parameter_units = (\n                _KCAL_PER_MOL_RADSQ,\n                _KCAL_PER_MOL_RADSQ,\n                _RADIANS,\n                _RADIANS,\n            )\n            ff_copy.potentials.append(new_potential)\n        else:\n            ff_copy.potentials.append(potential)\n    return ff_copy\n</code></pre>"},{"location":"reference/parameterizer/#bespokefit_smee.parameterizer.linearize_propertorsions","title":"linearize_propertorsions","text":"<pre><code>linearize_propertorsions(\n    ff: TensorForceField, device_type: str\n) -&gt; TensorForceField\n</code></pre> <p>Linearize the proper torsion parameters in the forcefield for more robust optimization</p> Source code in <code>bespokefit_smee/parameterizer.py</code> <pre><code>def linearize_propertorsions(\n    ff: smee.TensorForceField, device_type: str\n) -&gt; smee.TensorForceField:\n    \"\"\"Linearize the proper torsion parameters in the forcefield for more robust optimization\"\"\"\n    ff_copy = copy.deepcopy(ff)\n    ff_copy.potentials = []\n    for potential in ff.potentials:\n        if potential.type in {\"ProperTorsions\"}:\n            new_potential = copy.deepcopy(potential)\n            new_potential.type = \"LinearProperTorsions\"\n            new_potential.fn = (\n                \"(k1+k2)*(1+cos(periodicity*theta-acos((k1-k2)/(k1+k2))))\"\n            )\n            new_potential.parameter_cols = (\n                \"k1\",\n                \"k2\",\n                \"periodicity\",\n                \"phase1\",\n                \"phase2\",\n                \"idivf\",\n            )\n            new_params = []\n            for param in potential.parameters:\n                k = param[0].item()\n                periodicity = param[1].item()\n                phase = param[2].item()\n                idivf = param[3].item()\n                dt = param.dtype\n                k1 = abs(k * 0.5 * (1 + math.cos(phase)))\n                k2 = abs(k * 0.5 * (1 - math.cos(phase)))\n                new_params.append([k1, k2, periodicity, 0.0, math.pi, idivf])\n            new_potential.parameters = torch.tensor(\n                new_params, dtype=dt, requires_grad=True, device=device_type\n            )\n            new_potential.parameter_units = (\n                _KCAL_PER_MOL,\n                _KCAL_PER_MOL,\n                _UNITLESS,\n                _RADIANS,\n                _RADIANS,\n                _UNITLESS,\n            )\n            ff_copy.potentials.append(new_potential)\n        else:\n            ff_copy.potentials.append(potential)\n    return ff_copy\n</code></pre>"},{"location":"reference/parameterizer/#bespokefit_smee.parameterizer.linearize_impropertorsions","title":"linearize_impropertorsions","text":"<pre><code>linearize_impropertorsions(\n    ff: TensorForceField, device_type: str\n) -&gt; TensorForceField\n</code></pre> <p>Linearize the improper torsion parameters in the forcefield for more robust optimization</p> Source code in <code>bespokefit_smee/parameterizer.py</code> <pre><code>def linearize_impropertorsions(\n    ff: smee.TensorForceField, device_type: str\n) -&gt; smee.TensorForceField:\n    \"\"\"Linearize the improper torsion parameters in the forcefield for more robust optimization\"\"\"\n    ff_copy = copy.deepcopy(ff)\n    ff_copy.potentials = []\n    for potential in ff.potentials:\n        if potential.type in {\"ImproperTorsions\"}:\n            new_potential = copy.deepcopy(potential)\n            new_potential.type = \"LinearImproperTorsions\"\n            new_potential.fn = (\n                \"(k1+k2)*(1+cos(periodicity*theta-acos((k1-k2)/(k1+k2))))\"\n            )\n            new_potential.parameter_cols = (\n                \"k1\",\n                \"k2\",\n                \"periodicity\",\n                \"phase1\",\n                \"phase2\",\n                \"idivf\",\n            )\n            new_params = []\n            for param in potential.parameters:\n                k = param[0].item()\n                periodicity = param[1].item()\n                phase = param[2].item()\n                idivf = param[3].item()\n                dt = param.dtype\n                k1 = abs(k * 0.5 * (1 + math.cos(phase)))\n                k2 = abs(k * 0.5 * (1 - math.cos(phase)))\n                new_params.append([k1, k2, periodicity, 0.0, math.pi, idivf])\n            new_potential.parameters = torch.tensor(\n                new_params, dtype=dt, device=device_type\n            )\n            new_potential.parameter_units = (\n                _KCAL_PER_MOL,\n                _KCAL_PER_MOL,\n                _UNITLESS,\n                _RADIANS,\n                _RADIANS,\n                _UNITLESS,\n            )\n            ff_copy.potentials.append(new_potential)\n        else:\n            ff_copy.potentials.append(potential)\n    return ff_copy\n</code></pre>"},{"location":"reference/settings/","title":"settings","text":""},{"location":"reference/settings/#bespokefit_smee.settings","title":"settings","text":"<p>Pydantic models which control/validate the settings.</p> <p>Classes:</p> <ul> <li> <code>TrainingConfig</code>           \u2013            <p>Configuration for the training process.</p> </li> </ul>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingConfig","title":"TrainingConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for the training process.</p> <p>Methods:</p> <ul> <li> <code>validate_device_type</code>             \u2013              <p>Ensure that the requested device type is available.</p> </li> <li> <code>validate_snapshots</code>             \u2013              <p>Ensure that the number of snapshots is divisible by the number of conformers.</p> </li> <li> <code>validate_data</code>             \u2013              <p>Validate the data field based on the method.</p> </li> <li> <code>from_yaml</code>             \u2013              <p>Load configuration from a YAML file.</p> </li> <li> <code>to_yaml</code>             \u2013              <p>Save configuration to a YAML file.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>n_test_snapshots_per_conformer</code>               (<code>int</code>)           \u2013            <p>Return the number of test snapshots per conformer.</p> </li> <li> <code>n_train_snapshots_per_conformer</code>               (<code>int</code>)           \u2013            <p>Return the number of training snapshots per conformer.</p> </li> <li> <code>run_md_fn</code>               (<code>GetDataFnType</code>)           \u2013            <p>Return the function to get data based on the selected method.</p> </li> <li> <code>pretty_string</code>               (<code>str</code>)           \u2013            <p>Return a pretty string representation of the configuration.</p> </li> </ul>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingConfig.n_test_snapshots_per_conformer","title":"n_test_snapshots_per_conformer  <code>property</code>","text":"<pre><code>n_test_snapshots_per_conformer: int\n</code></pre> <p>Return the number of test snapshots per conformer.</p>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingConfig.n_train_snapshots_per_conformer","title":"n_train_snapshots_per_conformer  <code>property</code>","text":"<pre><code>n_train_snapshots_per_conformer: int\n</code></pre> <p>Return the number of training snapshots per conformer.</p>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingConfig.run_md_fn","title":"run_md_fn  <code>property</code>","text":"<pre><code>run_md_fn: GetDataFnType\n</code></pre> <p>Return the function to get data based on the selected method.</p>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingConfig.pretty_string","title":"pretty_string  <code>property</code>","text":"<pre><code>pretty_string: str\n</code></pre> <p>Return a pretty string representation of the configuration.</p>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingConfig.validate_device_type","title":"validate_device_type  <code>classmethod</code>","text":"<pre><code>validate_device_type(value: TorchDevice) -&gt; TorchDevice\n</code></pre> <p>Ensure that the requested device type is available.</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@field_validator(\"device_type\")\n@classmethod\ndef validate_device_type(cls, value: TorchDevice) -&gt; TorchDevice:\n    \"\"\"Ensure that the requested device type is available.\"\"\"\n    if value == \"cuda\" and not torch.cuda.is_available():\n        raise ValueError(\"CUDA is not available on this system.\")\n\n    if value == \"cpu\":\n        warnings.warn(\n            \"Using CPU for training. This may be slow. Consider using CUDA if available.\",\n            UserWarning,\n            stacklevel=2,\n        )\n\n    return value\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingConfig.validate_snapshots","title":"validate_snapshots","text":"<pre><code>validate_snapshots() -&gt; TrainingConfig\n</code></pre> <p>Ensure that the number of snapshots is divisible by the number of conformers.</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_snapshots(self) -&gt; \"TrainingConfig\":\n    \"\"\"Ensure that the number of snapshots is divisible by the number of conformers.\"\"\"\n    if self.n_train_snapshots % self.n_conformers != 0:\n        raise ValueError(\n            f\"Number of training snapshots ({self.n_train_snapshots}) must be divisible by the number of conformers ({self.n_conformers}).\"\n        )\n    if self.n_test_snapshots % self.n_conformers != 0:\n        raise ValueError(\n            f\"Number of test snapshots ({self.n_test_snapshots}) must be divisible by the number of conformers ({self.n_conformers}).\"\n        )\n    return self\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingConfig.validate_data","title":"validate_data","text":"<pre><code>validate_data() -&gt; TrainingConfig\n</code></pre> <p>Validate the data field based on the method.</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_data(self) -&gt; \"TrainingConfig\":\n    \"\"\"Validate the data field based on the method.\"\"\"\n    if self.method == \"data\" and self.data is None:\n        raise ValueError(\n            \"If method is 'data', the data field must be a valid path.\"\n        )\n    elif self.method != \"data\" and self.data is not None:\n        raise ValueError(\"If method is not 'data', the data field must be None.\")\n\n    return self\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingConfig.from_yaml","title":"from_yaml  <code>classmethod</code>","text":"<pre><code>from_yaml(\n    yaml_path: PathLike = DEFAULT_CONFIG_PATH,\n) -&gt; TrainingConfig\n</code></pre> <p>Load configuration from a YAML file.</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@classmethod\ndef from_yaml(cls, yaml_path: PathLike = DEFAULT_CONFIG_PATH) -&gt; \"TrainingConfig\":\n    \"\"\"Load configuration from a YAML file.\"\"\"\n    with open(yaml_path, \"r\") as file:\n        config_data = yaml.safe_load(file)\n    return cls(**config_data)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingConfig.to_yaml","title":"to_yaml","text":"<pre><code>to_yaml(yaml_path: PathLike = DEFAULT_CONFIG_PATH) -&gt; None\n</code></pre> <p>Save configuration to a YAML file.</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>def to_yaml(self, yaml_path: PathLike = DEFAULT_CONFIG_PATH) -&gt; None:\n    \"\"\"Save configuration to a YAML file.\"\"\"\n    data = self.model_dump()\n    # Convert Path objects to strings for YAML serialisation\n    for key, value in data.items():\n        if isinstance(value, Path):\n            data[key] = str(value)\n    with open(yaml_path, \"w\") as file:\n        yaml.dump(data, file, default_flow_style=False, sort_keys=False)\n</code></pre>"},{"location":"reference/train/","title":"train","text":""},{"location":"reference/train/#bespokefit_smee.train","title":"train","text":"<p>Apply OpenFF parameters to molecule, cluster conformers by RMSD and train</p> <p>Functions:</p> <ul> <li> <code>train</code>             \u2013              <p>Train a bespoke force field according to the provided configuration.</p> </li> </ul>"},{"location":"reference/train/#bespokefit_smee.train.train","title":"train","text":"<pre><code>train(config: TrainingConfig) -&gt; None\n</code></pre> <p>Train a bespoke force field according to the provided configuration.</p> <p>Parameters:     config  : TrainingConfig         Configuration object containing all the necessary parameters for training.</p> Source code in <code>bespokefit_smee/train.py</code> <pre><code>def train(config: TrainingConfig) -&gt; None:\n    \"\"\"\n    Train a bespoke force field according to the provided configuration.\n\n    Parameters:\n        config  : TrainingConfig\n            Configuration object containing all the necessary parameters for training.\n    \"\"\"\n    # Summarise input parameters\n    logger.info(f\"Training settings:\\n{config.pretty_string}\")\n\n    # Save config to YAML file\n    config.to_yaml(yaml_path=config.output_dir / DEFAULT_CONFIG_PATH)\n\n    timestep_ps = config.timestep / 1000  # Convert to ps\n\n    # Parameterize the molecule and output the forcefield to a file\n    mol = openff.toolkit.Molecule.from_smiles(\n        config.smiles, allow_undefined_stereo=True, hydrogens_are_explicit=False\n    )\n    VdW_forcefield = openff.toolkit.ForceField(config.initial_force_field)\n    old_force_field, trainable, topology = build_parameters(\n        mol,\n        VdW_forcefield,\n        config.ml_potential,\n        config.linear_harmonics,\n        config.linear_torsions,\n        config.use_modified_seminaro,\n        config.modified_seminario_finite_step / 10,  # Convert to nm\n        config.modified_seminario_vib_scaling,\n        config.modified_seminario_tolerance,\n        device_type=config.device_type,\n    )\n\n    # Move to the requested device (not strictly necessary if on CPU)\n    trainable_parameters = trainable.to_values().to((config.device_type))\n    topology = topology.to(config.device_type)\n\n    # Convert topology assignment tensors to dense - needed for some reason for hessian calc\n    for param in topology.parameters.values():\n        param.assignment_matrix = param.assignment_matrix.to_dense()\n\n    off_force_field = convert_to_smirnoff(\n        trainable.to_force_field(trainable_parameters), base=VdW_forcefield\n    )\n    off_force_field.to_file(\"default.offxml\")\n\n    # get the inital training data\n    if config.method == \"data\":\n        dataset = datasets.Dataset.load_from_disk(config.data)\n    else:\n        dataset = config.run_md_fn(\n            mol,\n            off_force_field,\n            config.ml_potential,\n            config.temperature,\n            timestep_ps,\n            config.n_train_snapshots_per_conformer,\n            config.n_conformers,\n            config.snapshot_interval,\n            config.n_equilibration_steps,\n            config.energy_upper_cutoff,\n            config.energy_lower_cutoff,\n            config.cluster_tolerance,\n            config.cluster_parallel,\n        )\n\n    with open(\"/dev/null\", \"w\") as f:\n        with redirect_stderr(f):\n            dataset.save_to_disk(\"data_it_0\")\n\n    # Generate the test set\n    if config.test_data_path is not None:\n        logger.info(\n            f\"Loading test set from {config.test_data_path} instead of generating it\"\n        )\n        dataset_test = datasets.Dataset.load_from_disk(config.test_data_path)\n    else:\n        logger.info(\"Generating Test Set with MLMD\")\n        dataset_test = get_data_MLMD(\n            mol,\n            off_force_field,\n            config.ml_potential,\n            config.temperature,\n            timestep_ps,\n            config.n_test_snapshots_per_conformer,\n            config.n_conformers,\n            config.snapshot_interval,\n            config.n_equilibration_steps,\n            config.energy_upper_cutoff,\n            config.energy_lower_cutoff,\n        )\n\n        with open(\"/dev/null\", \"w\") as f:\n            with redirect_stderr(f):\n                dataset_test.save_to_disk(\"data_test\")\n\n    # Generate the Energy Scatter Plot\n    energy_mean, energy_SD, forces_mean, forces_SD = write_scatter(\n        dataset_test,\n        trainable.to_force_field(trainable_parameters),\n        topology,\n        config.device_type,\n        \"default.scat\",\n    )\n\n    for iteration in tqdm(\n        range(config.n_iterations),\n        leave=False,\n        colour=\"magenta\",\n        desc=\"Iterating the Fit\",\n    ):\n        iterate_training_fns = {\n            \"lm\": _iterate_training_levenberg_marquardt,\n            \"adam\": _iterate_training_adam,\n        }\n        trainable_parameters, trainable = iterate_training_fns[config.optimiser](\n            trainable_parameters,\n            trainable,\n            topology,\n            dataset,\n            dataset_test,\n            config,\n            iteration,\n        )\n\n        summary_output = f\"Summary for Iteration {iteration + 1}\".center(88, \"=\")\n        summary_output += \"\\n\"\n        summary_output += \"Parameterization\".center(88, \"=\")\n        summary_output += \"\\n\"\n        summary_output += \"\\n\"\n        for potential_type in trainable._param_types:\n            summary_output += get_potential_comparison(\n                old_force_field.potentials_by_type[potential_type],\n                trainable.to_force_field(trainable_parameters).potentials_by_type[\n                    potential_type\n                ],\n            )\n            old_force_field.potentials_by_type[potential_type].parameters = copy.copy(\n                trainable.to_force_field(trainable_parameters)\n                .potentials_by_type[potential_type]\n                .parameters\n            )\n        # Output the forcefield to a file\n        off_force_field = convert_to_smirnoff(\n            trainable.to_force_field(trainable_parameters), base=VdW_forcefield\n        )\n        off_force_field.to_file(\"trained-\" + str(iteration) + \".offxml\")\n        # Generate the Energy Scatter Plot and summarize convergence\n        energy_mean_new, energy_SD_new, forces_mean_new, forces_SD_new = write_scatter(\n            dataset_test,\n            trainable.to_force_field(trainable_parameters),\n            topology,\n            config.device_type,\n            \"trained-\" + str(iteration) + \".scat\",\n        )\n        logger.info(\"\")\n        logger.info(\"\")\n        logger.info(\"Convergence\".center(88, \"=\"))\n        logger.info(\"\")\n        logger.info(\n            f\"    Energy Error (Mean): {energy_mean:10.3e}-&gt;{energy_mean_new:10.3e} : Change = {energy_mean_new - energy_mean:10.3e}\"\n        )\n        logger.info(\n            f\"                 (SD):   {energy_SD:10.3e}-&gt;{energy_SD_new:10.3e} : Change = {energy_SD_new - energy_SD:10.3e}\"\n        )\n        logger.info(\n            f\"    Forces Error (Mean): {forces_mean:10.3e}-&gt;{forces_mean_new:10.3e} : Change = {forces_mean_new - forces_mean:10.3e}\"\n        )\n        logger.info(\n            f\"                 (SD):   {forces_SD:10.3e}-&gt;{forces_SD_new:10.3e} : Change = {forces_SD_new - forces_SD:10.3e}\"\n        )\n        logger.info(\"\")\n        energy_mean, energy_SD = energy_mean_new, energy_SD_new\n        forces_mean, forces_SD = forces_mean_new, forces_SD_new\n\n        # Get the next iteration of training data, unless the loop is finished\n        if iteration + 1 &lt; config.n_iterations:\n            get_data_fn = config.run_md_fn if config.method != \"data\" else get_data_MMMD\n\n            new_dataset = get_data_fn(\n                mol,\n                off_force_field,\n                config.ml_potential,\n                config.temperature,\n                timestep_ps,\n                config.n_train_snapshots_per_conformer,\n                config.n_conformers,\n                config.snapshot_interval,\n                config.n_equilibration_steps,\n                config.energy_upper_cutoff,\n                config.energy_lower_cutoff,\n                config.cluster_tolerance,\n                config.cluster_parallel,\n            )\n\n            if config.memory:\n                dataset = datasets.combine.concatenate_datasets([dataset, new_dataset])\n            else:\n                dataset = new_dataset\n\n            with open(\"/dev/null\", \"w\") as f:\n                with redirect_stderr(f):\n                    dataset.save_to_disk(\"data_it_\" + str(iteration))\n</code></pre>"},{"location":"reference/writers/","title":"writers","text":""},{"location":"reference/writers/#bespokefit_smee.writers","title":"writers","text":"<p>WRITERS:</p> <p>Output functions for run-fit</p>"},{"location":"reference/utils/","title":"Index","text":""},{"location":"reference/utils/#bespokefit_smee.utils","title":"utils","text":"<p>Utilities for the bespokefit_smee package.</p> <p>Modules:</p> <ul> <li> <code>aimnet2</code>           \u2013            <p>Utilities for working with AIMNet2. Mainly taken from</p> </li> <li> <code>typing</code>           \u2013            <p>Typing utilities for the bespokefit_smee package.</p> </li> </ul>"},{"location":"reference/utils/aimnet2/","title":"aimnet2","text":""},{"location":"reference/utils/aimnet2/#bespokefit_smee.utils.aimnet2","title":"aimnet2","text":"<p>Utilities for working with AIMNet2. Mainly taken from https://github.com/openmm/openmm-ml/pull/64 and https://github.com/SimonBoothroyd/befit/blob/main/befit/utils/aimnet2.py</p> <p>See discussion at https://github.com/isayevlab/AIMNet2/issues/15 re ensemble models.</p> <p>See https://github.com/isayevlab/aimnetcentral/blob/47969eb3e29e34824d82a648dd756669c875ecdb/scripts/compile/compile_off.yaml for available models. May compile the ensemble models in future.</p> <p>Classes:</p> <ul> <li> <code>AIMNet2PotentialImplFactory</code>           \u2013            <p>This is the factory that creates AIMNet2PotentialImpl objects.</p> </li> <li> <code>AIMNet2PotentialImpl</code>           \u2013            <p>This is the MLPotentialImpl implementing the AIMNet2 potential.</p> </li> </ul>"},{"location":"reference/utils/aimnet2/#bespokefit_smee.utils.aimnet2.AIMNet2PotentialImplFactory","title":"AIMNet2PotentialImplFactory","text":"<p>               Bases: <code>MLPotentialImplFactory</code></p> <p>This is the factory that creates AIMNet2PotentialImpl objects.</p>"},{"location":"reference/utils/aimnet2/#bespokefit_smee.utils.aimnet2.AIMNet2PotentialImpl","title":"AIMNet2PotentialImpl","text":"<pre><code>AIMNet2PotentialImpl(name: str)\n</code></pre> <p>               Bases: <code>MLPotentialImpl</code></p> <p>This is the MLPotentialImpl implementing the AIMNet2 potential.</p> Source code in <code>bespokefit_smee/utils/aimnet2.py</code> <pre><code>def __init__(self, name: str):\n    self.name = name\n</code></pre>"},{"location":"reference/utils/typing/","title":"typing","text":""},{"location":"reference/utils/typing/#bespokefit_smee.utils.typing","title":"typing","text":"<p>Typing utilities for the bespokefit_smee package.</p>"}]}