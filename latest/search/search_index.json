{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"Bespokefit_smee <p>Generate a Bespoke Force-Field Parametrization Quickly and Reliably</p>"},{"location":"#newcastle-university-uk-cole-group","title":"Newcastle University UK - Cole Group","text":""},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>What is Bespokefit_smee?<ul> <li>In-Detail</li> </ul> </li> <li>Installation</li> <li>Running</li> </ul>"},{"location":"#what-is-bespokefit_smee","title":"What is Bespokefit_smee?","text":"<p>Bespokefit_smee is a Force-Field parametrization tool. For a given molecule, it will generate a data set of conformers using machine learning models in OpenMM-ML simulations. This dataset is used to minimize the Force-Field parametrization.</p>"},{"location":"#in-detail","title":"In Detail","text":"<p>From a SMILES string, we generate a initial parametrization using a default open-ff force field - and optionally, adding in modified-Seminario derived bond and angle force constants. This is used to generate a dataset of conformers by running either ML-Potential MD of Force-Field MD and grabbing a number of snapshots. For every snapshot, the energies and forces are taken using the ML-Potental.</p> <p>This dataset is used to minimize the given force field parameters using the ADAM stochastic optimization method, where the loss function is the squared difference between energies and forces for the conformer dataset predicted by the force-field parametrization and the stored values calculated with the ML-potential.</p> <p>After a given number of epochs, the new parametrization is stored. The new force-field is used to generate another set of MD snapshots, which are used in the same way to further optimize the force field. This continues for a given number of iterations, where the relative reduction is error is tracked. The number of iterations should be increased up to convergence.</p> <p>Four methods for generating the initial dataset are implemented:</p> <p>1 - \"DATA\" : Read the dataset from a file</p> <p>2 - \"MLMD\" : Run the ML-Potential MD to get the snapshots. This is the most expensive option.</p> <p>3 - \"MMMD\" : Run Force-Field MD using the initial guess to generate the snapshots. Then use the ML-Potential to generate energies and forces</p> <p>4 - \"cMMMD\" : Run Force-Field MD using the initial guess to generate the snapshots. Cluster the snapshots with respect to their pairwise RMSD and then use the ML-Potential to generate energies and forces</p> <p>The functional form of the force-field is as follows:</p> <ul> <li>Bonds and angles are defined by a harmonic function, \\(u(x;k,x_0)=\\frac{k}{2}\\left(x-x_0\\right)^2\\), where the position of the minimum, \\(x_0\\), and the magnitude, \\(k\\), are the fitting parameters.</li> <li>Proper and improper torsions are defined by a set of cosine functions, \\(u_p(\\phi;k,\\phi_0)=k\\left(1+\\cos{\\left(p\\phi-\\phi_0\\right)}\\right)\\), where the phase, \\(\\phi_0\\), and the magnitude, \\(k\\), are the fitted parameters. Here, proper torsions are expanded to include four periodicities, whereas improper torsions include only one. It is also noted that for symmetry, the phase \\(\\phi_0\\) is expected to be either 0 or \\(\\pi\\)</li> </ul> <p>To stabilize and speed up convergence of the parameter fitting, these potentials are linearized.</p> <p>The linearization of the harmonic terms followed the approach by espaloma, where the minimum is assumed to be within a window given by \\(x_1\\) and \\(x_2\\), such that the fitting parameters may by remapped onto linear terms,</p> \\[k_1=k\\frac{x_2-x_0}{x_2-x_1} \\quad\\text{and}\\quad k_2=k\\frac{x_0-x_1}{x_2-x_1}\\] <p>These terms give the original parameters via,</p> \\[k=k_1+k_2 \\quad\\text{and}\\quad x_0=\\frac{k_1x_1+k_2x_2}{k_1+k_2}\\] <p>Crucially, the gradient along \\(k_1\\) and \\(k_2\\) behaves more reliably and so the parameters minimize faster.</p> <p>In a similar way, the cosine functions are linearized by defining a phase window of 0 to \\(\\pi\\), such that the parameters may be mapped onto,</p> \\[k_0=\\frac{k}{2}\\left(1+\\cos{\\phi_0}\\right) \\quad\\text{and}\\quad k_{\\pi}=\\frac{k}{2}\\left(1-\\cos{\\phi_0}\\right)\\] <p>which yield the original parameters via,</p> \\[k=k_0+k_{\\pi} \\quad\\text{and}\\quad \\cos{\\phi_0}=\\frac{k_0-k_{\\pi}}{k_0+k_{\\pi}}\\] <p>Again, the gradient along \\(k_0\\) and \\(k_{\\pi}\\) is more reliable and the parametrization proceed faster.</p>"},{"location":"#installation","title":"Installation","text":"<p>The easiest way to install Bespokefit_smee is with conda:</p> <p><pre><code>   git clone https://github.com/thomasjamespope/bespokefit_smee.git\n   cd bespokefit_smee\n   mamba env create -n bespokefit_smee --file enviroment.yaml\n   mamba activate bespokefit_smee\n   pip install mace-torch\n</code></pre> In addition, an updated version on the package smee is required: <pre><code>   mamba uninstall smee\n   mamba install pydantic-units msgpack-python nnpops\n   git clone https://github.com/thomasjamespope/smee\n   cd smee\n   pip install .\n</code></pre></p>"},{"location":"#running","title":"Running","text":"<p>Running Bespokefit_smee is easy. Simply determine the SMILES string of your molecule are run: <pre><code>    python bespokefit_smee.py --smiles SMILES [options]\n</code></pre> where a full list of options follows. Note, only the SMILES string is required. The other options have reasonable defaults.</p> Input parameter Variable Default Description <code>--smiles</code> str None SMILES string of the molecule <code>--method</code> str MMMD Method for generating data: (DATA,MLMD,MMMD,cMMMD) <code>--N_epochs</code> int 1000 Number of epochs in the ML fit <code>--learning_rate</code> float 0.1 Learning Rate in the ML fit <code>--learning_rate_decay</code> float 0.99 Learning Rate Decay <code>--learning_rate_decay_step</code> int 10 Learning Rate Decay Step <code>--loss_force_weight</code> float 1e5 Scaling Factor for the Force loss term <code>--force_field_init</code> str openff-2.2.0.offxml Starting guess force field <code>--modSem</code> <code>--no-modSem</code> <code>--modSem</code> Use mod-Seminario method to initialize the Force Field <code>--linear_harmonics</code> <code>--no-linear_harmonics</code> <code>--linear_harmonics</code> Linearize the Harmonic potentials in the Force Field <code>--linear_torsions</code> <code>--no-linear_torsions</code> <code>--linear_torsions</code> Linearize the Torsion potentials in the Force Field <code>--MLMD_potential</code> str mace-off23-small Name of the MD potential used <code>--N_train</code> int 1000 Number of data-points in training set <code>--N_test</code> int 1000 Number of data-points in test set <code>--N_conformers</code> int 10 Number of Starting Conformers <code>--N_iterations</code> int 5 Number of ML Iterations Performed <code>--memory</code> <code>--no-memory</code> <code>--memory</code> Retain data upon iteration <code>--MD_stepsize</code> int 10 Number of Time Steps Between MD Snapshots <code>--MD_startup</code> int 100 Number of Time Steps Ignored <code>--MD_temperature</code> int 500 Temperature in Kelvin <code>--MD_dt</code> float 1.0 MD Stepsize in femtoseconds <code>--MD_energy_lower_cutoff</code> float 1.0 Lower bound for the energy cut-off function in kcal/mol <code>--MD_energy_upper_cutoff</code> float 10.0 Upper bound for the energy cut-off function in kcal/mol <code>--Cluster_tolerance</code> float 0.075 Tolerance used in the RMSD clustering <code>--Cluster_Parallel</code> int 1 MPI nodes used in the RMSD clustering <code>--data</code> str train_data Location of pre-calculated data set <code>--modSem_finite_step</code> float 0.005291772 Finite Step to Calculate Hessian in Ang <code>--modSem_vib_scaling</code> float 0.957 Vibrational Scaling Parameter <code>--modSem_tolerance</code> float 0.0001 Tolerance for the geometry optimizer"},{"location":"changelog/","title":"Changelog","text":""},{"location":"development/","title":"Development","text":""},{"location":"development/#writing-code","title":"Writing Code","text":"<p>To create a development environment, you must have <code>mamba</code> installed.</p> <p>A development conda environment can be created and activated with:</p> <pre><code>make env\nmamba activate red\n</code></pre> <p>Some handy <code>make</code> commands are available: <pre><code>make lint # Lint the codebase with Ruff\nmake format # Format the codebase with Ruff\nmake type-check # Type-check the codebase with Mypy\nmake test # Run the unit tests with Pytest\n</code></pre></p> <p>To serve the documentation locally:</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"development/#publishing","title":"Publishing","text":""},{"location":"development/#pypi","title":"PyPI","text":"<p>There is a GitHub Actions workflow that will automatically publish to PyPI when a new tag is pushed: <pre><code>git tag &lt;new version&gt;\ngit push origin &lt;new version&gt;\n</code></pre></p>"}]}